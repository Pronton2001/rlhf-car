{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430d5435",
   "metadata": {
    "id": "f7f64953"
   },
   "source": [
    "### Training RL Policies using L5Kit Closed-Loop Environment\n",
    "\n",
    "This notebook describes how to train RL policies for self-driving using our gym-compatible closed-loop environment.\n",
    "\n",
    "We will be using [Proximal Policy Optimization (PPO)](https://arxiv.org/abs/1707.06347) algorithm as our reinforcement learning algorithm, as it not only demonstrates remarkable performance but it is also empirically easy to tune.\n",
    "\n",
    "The PPO implementation in this notebook is based on [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3) framework, a popular framework for training RL policies. Note that our environment is also compatible with [RLlib](https://docs.ray.io/en/latest/rllib.html), another popular frameworks for the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5501b1",
   "metadata": {
    "id": "ulK_RDB4e_gx"
   },
   "source": [
    "ref: \n",
    "([rllib] Best workflow to train, save, and test agent #9123\n",
    ")[https://github.com/ray-project/ray/issues/9123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bbc82f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smZ0MKsHE2_s",
    "outputId": "631f2d2d-38ee-45ba-f658-b7d11c59139b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = '/workspace/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ffe0e",
   "metadata": {
    "id": "585b1fe7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "# from stable_baselines3.common.env_util import make_vec_env\n",
    "# from stable_baselines3.common.utils import get_linear_fn\n",
    "# from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "# from l5kit.environment.feature_extractor import CustomFeatureExtractor\n",
    "# from l5kit.environment.callbacks import L5KitEvalCallback\n",
    "from l5kit.environment.envs.l5_env import SimulationConfigGym, GymStepOutput, L5Env\n",
    "\n",
    "from l5kit.visualization.visualizer.zarr_utils import episode_out_to_visualizer_scene_gym_cle\n",
    "from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from bokeh.io import output_notebook, show\n",
    "from l5kit.environment.gym_metric_set import L2DisplacementYawMetricSet, CLEMetricSet\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gym\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import ray\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8e8a2",
   "metadata": {
    "id": "xHfH5HGWoTD7",
    "tags": []
   },
   "source": [
    "## Init ray and env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f70ad",
   "metadata": {
    "id": "2ea81f77",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset is assumed to be on the folder specified\n",
    "# in the L5KIT_DATA_FOLDER environment variable\n",
    "from l5kit.configs import load_config_data\n",
    "\n",
    "# get environment config\n",
    "env_config_path = '/workspace/source/configs/gym_config84.yaml'\n",
    "cfg = load_config_data(env_config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e7093-60b8-40d4-be53-6f2091437d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newYorkTz = pytz.timezone(\"Asia/Ho_Chi_Minh\") \n",
    "date = datetime.datetime.now(newYorkTz).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "ray_result_logdir = '/workspace/datasets/ray_results/' + date\n",
    "\n",
    "ray.init(num_cpus=4, ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f59594b",
   "metadata": {
    "id": "eBwt9neMoj9h",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Customize my model\n",
    "SAC: https://github.com/ray-project/ray/blob/dfb9689701361cfd18f383e0a3edeed6baf81abb/rllib/agents/sac/sac_torch_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a14aa",
   "metadata": {
    "id": "fs23j_7Som37",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNCNN(SACTorchModel):\n",
    "    \"\"\"\n",
    "    Simple Convolution agent that calculates the required linear output layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        super().__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        # raise ValueError(obs_space.shape)\n",
    "        self._num_objects = obs_space.shape[2] # num_of_channels of input, size x size x channels\n",
    "        self._num_actions = num_outputs\n",
    "        self._feature_dim = model_config[\"custom_model_config\"]['feature_dim']\n",
    "\n",
    "        # linear_flatten = np.prod(obs_space.shape[:2])*64\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(self._num_objects, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            nn.GroupNorm(4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            nn.GroupNorm(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=1568, out_features=self._feature_dim),\n",
    "            # layer_init(nn.Conv2d(self._num_objects, 32, 3, padding=1)),\n",
    "            # nn.ReLU(),\n",
    "            # layer_init(nn.Conv2d(32, 64, 3, padding=1)),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Flatten(),\n",
    "            # layer_init(nn.Linear(linear_flatten, 1024)),\n",
    "            # nn.ReLU(),\n",
    "            # layer_init(nn.Linear(1024, 512)),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self._actor_head = nn.Sequential(\n",
    "            # layer_init(nn.Linear(512, 256), std=0.01),\n",
    "            # nn.ReLU(),\n",
    "            # layer_init(nn.Linear(256, self._num_actions), std=0.01)\n",
    "            nn.Linear(self._feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self._num_actions),\n",
    "        )\n",
    "\n",
    "        self._critic_head = nn.Sequential(\n",
    "            # layer_init(nn.Linear(512, 1), std=0.01)\n",
    "            nn.Linear(self._feature_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs_transformed = input_dict['obs'].permute(0, 3, 1, 2) # 32 x 112 x 112 x 7 [B, size, size, channels]\n",
    "        network_output = self.network(obs_transformed)\n",
    "        value = self._critic_head(network_output)\n",
    "        self._value = value.reshape(-1)\n",
    "        logits = self._actor_head(network_output)\n",
    "        return logits, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return self._value\n",
    "    def get_policy_output(self, , input_dict, state, seq_lens):\n",
    "        return forward()\n",
    "    def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e32c7d",
   "metadata": {
    "id": "j1cg5X5TotDS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.rllib.models import ModelCatalog\n",
    "ModelCatalog.register_custom_model(\n",
    "        \"GN_CNN_torch_model\", GNCNN\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fdd05",
   "metadata": {
    "id": "2cead394"
   },
   "source": [
    "## Define Training and Evaluation Environments\n",
    "\n",
    "**Training**: We will be training the PPO policy on episodes of length 32 time-steps. We will have 4 sub-processes (training environments) that will help to parallelize and speeden up episode rollouts. The *SimConfig* dataclass will define the parameters of the episode rollout: like length of episode rollout, whether to use log-replayed agents or simulated agents etc.\n",
    "\n",
    "**Evaluation**: We will evaluate the performance of the PPO policy on the *entire* scene (~248 time-steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c4a2f",
   "metadata": {
    "id": "0CAZm9UDo1C0",
    "tags": []
   },
   "source": [
    "## Customize gym env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29286e2",
   "metadata": {
    "id": "IJC1ix47g1Y4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class L5EnvWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, raster_size = 112, n_channels = 7):\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.n_channels = n_channels\n",
    "        self.raster_size = raster_size\n",
    "        obs_shape = (self.raster_size, self.raster_size, self.n_channels)\n",
    "        self.observation_space =gym.spaces.Box(low=0, high=1, shape=obs_shape, dtype=np.float32)\n",
    "\n",
    "    def step(self, action:  np.ndarray) -> GymStepOutput:\n",
    "        # return GymStepOutput(obs, reward[\"total\"], done, info)\n",
    "        output =  self.env.step(action)\n",
    "        onlyImageState = output.obs['image'].reshape(self.raster_size, self.raster_size, self.n_channels)\n",
    "        return GymStepOutput(onlyImageState, output.reward, output.done, output.info)\n",
    "\n",
    "    def reset(self) -> Dict[str, np.ndarray]:\n",
    "        return self.env.reset()['image'].reshape(self.raster_size, self.raster_size, self.n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a536b3f",
   "metadata": {
    "id": "XfXbbfjCg3aw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "train_eps_length = 32\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "# Register , how your env should be constructed (always with 5, or you can take values from the `config` EnvContext object):\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "\n",
    "tune.register_env(\"L5-CLE-V0\", lambda config: L5Env(**env_kwargs))\n",
    "tune.register_env(\"L5-CLE-V1\", lambda config: L5EnvWrapper(env = L5Env(**env_kwargs), \\\n",
    "                                                           raster_size= cfg['raster_params']['raster_size'][0], \\\n",
    "                                                           n_channels = 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa56982",
   "metadata": {
    "id": "rg8sxEnanVxL",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62938d37",
   "metadata": {
    "id": "LlFBhHgZfx5f",
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.integrations.wandb import setup_wandb\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '/DATA/rllib_ppo_policy_training.ipynb'!wandb login 083592c84134c040dcca598c644c348d32540a08\n",
    "import wandb ## ref\n",
    "\n",
    "Resume stop tune: https://docs.ray.io/en/latest/tune/tutorials/tune-stopping.html\n",
    "\n",
    "tune.Tuner analysis: https://docs.ray.io/en/latest/rllib/rllib-training.html#basic-python-api\n",
    "\n",
    "get best result, load from dir: https://docs.ray.io/en/master/tune/examples/tune_analyze_results.html#trial-level-analysis-working-with-an-individual-result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d153be-1e42-4a57-8463-d50ce0dfcf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login 083592c84134c040dcca598c644c348d32540a08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725e0e9-778f-4a31-a1e3-245f2d4f83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.integrations.wandb import setup_wandb\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '/DATA/rllib_sac_policy_training.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a62fa8-70dd-453d-b3da-ae2b045fde2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"l5kit2\", reinit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b7218",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gbfV227Jct2l",
    "outputId": "fd5c0af4-ad87-4a5d-a526-58dfad3b8646"
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/' + date\n",
    "\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'target_network_update_freq': 5,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'PrioritizedReplayBuffer',\n",
    "        'capacity': int(4e5),\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 1000,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    'store_buffer_in_checkpoints' : True,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 32,\n",
    "    'gamma': 0.8,\n",
    "}\n",
    "\n",
    "result_grid = tune.Tuner(\n",
    "    \"SAC\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 0, 'timesteps_total': int(6e6)},\n",
    "        local_dir=ray_result_logdir,\n",
    "        checkpoint_config=air.CheckpointConfig(num_to_keep=2, checkpoint_frequency = 10, checkpoint_score_attribute = 'episode_reward_mean')\n",
    "        ),\n",
    "    param_space=config_param_space).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164ab57-b068-4b75-ab94-24cdbff83d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "\n",
    "hcmTz = pytz.timezone(\"Asia/Ho_Chi_Minh\") \n",
    "date = datetime.datetime.now(hcmTz).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/' + date\n",
    "\n",
    "lr = 3e-3\n",
    "lr_start = 3e-4\n",
    "lr_end = 3e-5\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'target_network_update_freq': 1,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "        'capacity': int(1e5),\n",
    "        \"worker_side_prioritization\": True,\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 8000,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    " \n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    # 'store_buffer_in_checkpoints' : False,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    'train_batch_size': 2048,\n",
    "    'training_intensity' : 32, # (4x 'natural' value = 8)\n",
    "    'gamma': 0.8,\n",
    "    'twin_q' : True,\n",
    "    \"lr\": 3e-4,\n",
    "    \"min_sample_timesteps_per_iteration\": 8000,\n",
    "}\n",
    "\n",
    "result_grid = tune.Tuner(\n",
    "    \"SAC\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 0, 'timesteps_total': int(4e6)},\n",
    "        local_dir=ray_result_logdir,\n",
    "        checkpoint_config=air.CheckpointConfig(num_to_keep=2, checkpoint_frequency = 10, checkpoint_score_attribute = 'episode_reward_mean'),\n",
    "        callbacks=[WandbLoggerCallback(project=\"l5kit2\", \n",
    "\t\t\t\t\t\tsave_checkpoints=True),],\n",
    "        ),\n",
    "        \n",
    "    param_space=config_param_space).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bd96b-13ef-416c-8113-499ebce65ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "\n",
    "hcmTz = pytz.timezone(\"Asia/Ho_Chi_Minh\") \n",
    "date = datetime.datetime.now(hcmTz).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/' + date\n",
    "\n",
    "lr = 3e-3\n",
    "lr_start = 3e-4\n",
    "lr_end = 3e-5\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'target_network_update_freq': 1,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "        'capacity': int(1e5),\n",
    "        \"worker_side_prioritization\": True,\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 8000,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    " \n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    # 'store_buffer_in_checkpoints' : False,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    'train_batch_size': 2048,\n",
    "    # 'training_intensity' : 1000,\n",
    "    'gamma': 0.8,\n",
    "    'twin_q' : True,\n",
    "    \"lr\": 3e-4,\n",
    "    \"min_sample_timesteps_per_iteration\": 8000,\n",
    "}\n",
    "\n",
    "result_grid = tune.Tuner(\n",
    "    \"SAC\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 0, 'timesteps_total': int(2e6)},\n",
    "        local_dir=ray_result_logdir,\n",
    "        checkpoint_config=air.CheckpointConfig(num_to_keep=2, checkpoint_frequency = 10, checkpoint_score_attribute = 'episode_reward_mean')\n",
    "        ),\n",
    "    param_space=config_param_space).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bf4329-c187-46e8-8658-bb867e5fc90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'target_network_update_freq': 1,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "        'capacity': int(1e5),\n",
    "        \"worker_side_prioritization\": True,\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 8000,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    " \n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    # 'store_buffer_in_checkpoints' : False,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    'train_batch_size': 2048,\n",
    "    # 'training_intensity' : 1000,\n",
    "    'gamma': 0.8,\n",
    "    'twin_q' : True,\n",
    "    \"lr\": 3e-4,\n",
    "    \"min_sample_timesteps_per_iteration\": 8000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2897c-ecd0-4402-be62-655d7f194e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_param_space['stop']['timesteps_total'] = 3e-5\n",
    "path_to_trained_agent_checkpoint = 'l5kit/ray_results/29-12-2022_07-47-22/SAC/SAC_L5-CLE-V1_5af7a_00000_0_2022-12-29_00-47-23/checkpoint_000249'\n",
    "from ray.rllib.algorithms.sac import SAC\n",
    "ray.tune.run(SAC, config=config_param_space, restore=path_to_trained_agent_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae5452-4d9c-47a7-bc98-1056a9d927c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/' + date\n",
    "lr = 3e-3\n",
    "lr_start = 3e-4\n",
    "lr_end = 3e-5\n",
    "\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'n_step': 1\n",
    "    'target_network_update_freq': 5,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "        'capacity': int(3e5),\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 256,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 32,\n",
    "    'gamma': 0.8,\n",
    "    \"lr_schedule\": [\n",
    "        [1e6, lr_start],\n",
    "        [2e6, lr_end],\n",
    "    ],\n",
    "    \"lr\": lr,\n",
    "}\n",
    "\n",
    "result_grid = tune.Tuner(\n",
    "    \"SAC\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 0, 'timesteps_total': int(3e6)},\n",
    "        local_dir=ray_result_logdir,\n",
    "        checkpoint_config=air.CheckpointConfig(num_to_keep=2, checkpoint_frequency = 10, checkpoint_score_attribute = 'episode_reward_mean')\n",
    "        ),\n",
    "    param_space=config_param_space).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28fe783",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RTK45EUeonWl",
    "outputId": "1a0ff185-7c8c-4cfb-8d1c-4dcb71cd7fb4"
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/29-12-2022_07-47-22'\n",
    "\n",
    "tuner = tune.Tuner.restore(\n",
    "    path=ray_result_logdir + '/SAC'\n",
    ")\n",
    "result = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f20c94-38cb-44a7-96ce-48ba11b430fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = result.get_best_result(metric=\"episode_reward_mean\", mode = 'max')\n",
    "best_checkpoint = best_result.checkpoint\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb196340-7ec2-471a-9857-1cd540a96a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_results = len(result)\n",
    "print(\"Number of results:\", num_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce9e89-8641-4897-97f8-7b90baf82edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_best_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3625c4c7-cc99-47ae-9a19-f70d10ca91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77798ffb-abfd-4021-888d-a66d51a03481",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da07f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = best_result.metrics_dataframe() \n",
    "result_df[['episode_reward_mean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8618e3",
   "metadata": {
    "id": "4fipqZymhM1l"
   },
   "source": [
    "NOTE: Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
    "\n",
    "2022-12-04 05:50:38,570\tINFO experiment_analysis.py:795 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
    "\n",
    "2022-12-04 05:50:39,684\tINFO trial_runner.py:601 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
    "2022-12-04 05:50:39,687\tINFO trial_runner.py:738 -- Using following checkpoint to resume: /content/drive/MyDrive/Colab Notebooks/l5kit/ray_results/PPO/experiment_state-2022-12-04_05-28-55.json\n",
    "\n",
    "2022-12-04 05:50:39,710\tWARNING trial_runner.py:743 -- Attempting to resume experiment from /content/drive/MyDrive/Colab Notebooks/l5kit/ray_results/PPO. This will ignore any new changes to the specification.\n",
    "\n",
    "2022-12-04 05:50:40,703\tINFO tune.py:668 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fed29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4p68J7JqSddH",
    "outputId": "c10e3423-caa6-48b5-caea-31fe9893fde5"
   },
   "outputs": [],
   "source": [
    "train_envs=2\n",
    "ray_result_logdir = '/content/drive/MyDrive/Colab Notebooks/l5kit/ray_results'\n",
    "# Create the Trainer.\n",
    "algo = ppo.PPO(\n",
    "        env=\"L5-CLE-V1\",\n",
    "        config={\n",
    "            \"framework\": \"torch\",\n",
    "            \"num_gpus\": 1,\n",
    "            \"num_workers\": 2,\n",
    "            \"num_envs_per_worker\": train_envs,\n",
    "            'num_sgd_iter': 5,\n",
    "            'sgd_minibatch_size': 256,\n",
    "            'num_cpus_per_worker': 0,  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "            \"model\": {\n",
    "                \"custom_model\": \"GN_CNN_torch_model\",\n",
    "                \"custom_model_config\": {'feature_dim':128},\n",
    "            },\n",
    "            '_disable_preprocessor_api': True,\n",
    "        },\n",
    "        logger_creator=custom_log_creator(os.path.expanduser(ray_result_logdir), 'L5_PPO')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b16aee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "OyKfMUNfpTfq",
    "outputId": "a6ff9bc8-f0b8-4e3b-c2aa-80d251494529"
   },
   "outputs": [],
   "source": [
    "checkpoint_path =  '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/'+ str(datetime.date.today())\n",
    "for i in range(1, 1000):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = algo.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 10 == 0:\n",
    "       checkpoint = algo.save(checkpoint_dir= checkpoint_path)\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff44cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvbCuZHCwh44",
    "outputId": "d9246d10-3c7f-4fc1-f17b-645061412323"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/2022-12-02/checkpoint_000130'\n",
    "config={\n",
    "            \"framework\": \"torch\",\n",
    "            \"num_gpus\": 1,\n",
    "            \"num_workers\": 2,\n",
    "            \"num_envs_per_worker\": train_envs,\n",
    "            'num_sgd_iter': 15,\n",
    "            'sgd_minibatch_size': 128,\n",
    "            'num_cpus_per_worker': 0,  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "            \"model\": {\n",
    "                \"custom_model\": \"GN_CNN_torch_model\",\n",
    "                \"custom_model_config\": {'feature_dim':128},\n",
    "            },\n",
    "            '_disable_preprocessor_api': True,\n",
    "        }\n",
    "algo = ppo.PPO(config=config, env='L5-CLE-V1')\n",
    "algo.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13a811",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eR892sUGybQR",
    "outputId": "4a39bb59-2025-4cca-b3ee-a031312eb0c3"
   },
   "outputs": [],
   "source": [
    "checkpoint_path =  '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/'+ str(datetime.date.today())\n",
    "for i in range(1, 1000):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = algo.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 10 == 0:\n",
    "       checkpoint = algo.save(checkpoint_dir= checkpoint_path)\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9cefd1",
   "metadata": {
    "id": "GnXlEIp3xktb"
   },
   "outputs": [],
   "source": [
    "checkpoint_path =  '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/'+ str(datetime.date.today())\n",
    "for i in range(1, 1000):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = algo.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 1 == 0:\n",
    "       checkpoint = algo.save(checkpoint_dir= checkpoint_path)\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea4f53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvrD01hihER4",
    "outputId": "40bfcbc9-a62c-49ba-f914-a3dbe934a2ea"
   },
   "outputs": [],
   "source": [
    "train_envs = 2\n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 1\n",
    "# config[\"framework\"] = 'tf2'\n",
    "config[\"num_workers\"] = 2\n",
    "config[\"num_envs_per_worker\"] = train_envs\n",
    "config['_disable_preprocessor_api'] = True,\n",
    "config[\"model\"][\"dim\"] = 112\n",
    "config[\"model\"][\"conv_filters\"] = [[64, 7, 3], [32, 11, 3], [32, 11, 3]]\n",
    "config['num_sgd_iter'] = 1\n",
    "config['sgd_minibatch_size'] = 256\n",
    "# config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "# config['env_config'] = env_kwargs \n",
    "# config[\"log_level\"] = 1\n",
    "# config[\"evaluation_interval\"] = 1 # change to 10000\n",
    "# config[\"evaluation_duration\"] = \"auto\"\n",
    "# config[\"evaluation_parallel_to_training\"] = True,\n",
    "# config[\"evaluation_duration_unit\"] = \"timesteps\"\n",
    "# config[\"evaluation_num_workers\"] = 3\n",
    "# config[\"enable_async_evaluation\"] = True,\n",
    "\n",
    "config[\"model\"][\"conv_activation\"] = 'relu'\n",
    "config[\"model\"][\"post_fcnet_hiddens\"] =  [256]\n",
    "config[\"model\"][\"post_fcnet_activation\"] = 'relu'\n",
    "# config[\"train_batch_size\"] = 200\n",
    "algo = ppo.PPO(config=config, env=\"L5-CLE-V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234eeb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ErrnMkgMFowP",
    "outputId": "70c40c5a-1b39-4324-fcfc-6bcc57464ec0"
   },
   "outputs": [],
   "source": [
    "checkpoint_path =  '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/'+ str(datetime.date.today())\n",
    "for i in range(1, 1000):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = algo.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 10 == 0:\n",
    "       checkpoint = algo.save(checkpoint_dir= checkpoint_path)\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d5b7dc",
   "metadata": {
    "id": "d24f956c"
   },
   "source": [
    "## Visualize the episode from the environment\n",
    "\n",
    "We can easily visualize the outputs obtained by rolling out episodes in the L5Kit using the Bokeh visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cd644-8532-4763-beb0-d3e598aa75c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_envs = 4\n",
    "lr = 3e-3\n",
    "lr_start = 3e-4\n",
    "lr_end = 3e-5\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 0,\n",
    "    # \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'target_network_update_freq': 1,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "        'capacity': int(1e5),\n",
    "        \"worker_side_prioritization\": True,\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 8000,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    " \n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    # 'store_buffer_in_checkpoints' : False,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    'train_batch_size': 2048,\n",
    "    'training_intensity' : 32, # (4x 'natural' value = 8)\n",
    "    'gamma': 0.8,\n",
    "    'twin_q' : True,\n",
    "    \"lr\": 3e-4,\n",
    "    \"min_sample_timesteps_per_iteration\": 8000,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95614028-6363-4200-b6f3-4df46d51ba1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "rollout_sim_cfg = SimulationConfigGym()\n",
    "rollout_sim_cfg.num_simulation_steps = 50\n",
    "\n",
    "env_kwargs = {'env_config_path': env_config_path, \n",
    "              'use_kinematic': True, \n",
    "              'sim_cfg': rollout_sim_cfg,  \n",
    "              'train': False, \n",
    "              'return_info': True}\n",
    "\n",
    "rollout_env = L5EnvWrapper(env = L5Env(**env_kwargs), \\\n",
    "                           raster_size= cfg['raster_params']['raster_size'][0], \\\n",
    "                           n_channels = 7,)\n",
    "tune.register_env(\"L5-CLE-V2\", \n",
    "                  lambda config: L5EnvWrapper(env = L5Env(**env_kwargs), \\\n",
    "                                              raster_size= cfg['raster_params']['raster_size'][0], \\\n",
    "                                              n_channels = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd1b71e-e4a7-46d4-9835-d22a0f01025e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.sac import SAC\n",
    "# checkpoint_path = 'l5kit/ray_results/01-01-2023_15-53-49/SAC/SAC_L5-CLE-V1_cf7bb_00000_0_2023-01-01_08-53-50/checkpoint_000170'\n",
    "checkpoint_path = '/workspace/datasets/ray_results/31-12-2022_07-53-04/SAC/SAC_L5-CLE-V1_7bae1_00000_0_2022-12-31_00-53-04/checkpoint_000360'\n",
    "algo = SAC(config=config_param_space, env='L5-CLE-V2')\n",
    "algo.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25991944",
   "metadata": {
    "id": "fcd2b424",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rollout_episode(model, env, idx = 0):\n",
    "    \"\"\"Rollout a particular scene index and return the simulation output.\n",
    "\n",
    "    :param model: the RL policy\n",
    "    :param env: the gym environment\n",
    "    :param idx: the scene index to be rolled out\n",
    "    :return: the episode output of the rolled out scene\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the reset_scene_id to 'idx'\n",
    "    env.set_reset_id(idx)\n",
    "    \n",
    "    # Rollout step-by-step\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while True:\n",
    "        action = model.compute_single_action(obs, deterministic=True)\n",
    "        obs, _, done, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # The episode outputs are present in the key \"sim_outs\"\n",
    "    sim_out = info[\"sim_outs\"][0]\n",
    "    return sim_out\n",
    "\n",
    "# Rollout one episode\n",
    "# sim_out = rollout_episode(model, rollout_env)\n",
    "# Rollout 5 episodes\n",
    "sim_outs =[]\n",
    "for i in range(100):\n",
    "    sim_outs.append(rollout_episode(algo, rollout_env, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbc2c9",
   "metadata": {
    "id": "7e383cff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# might change with different rasterizer\n",
    "map_API = rollout_env.dataset.rasterizer.sem_rast.mapAPI\n",
    "\n",
    "def visualize_outputs(sim_outs, map_API):\n",
    "    for sim_out in sim_outs: # for each scene\n",
    "        vis_in = episode_out_to_visualizer_scene_gym_cle(sim_out, map_API)\n",
    "        # print(vis_in)\n",
    "        # break\n",
    "        show(visualize(sim_out.scene_id, vis_in))\n",
    "\n",
    "output_notebook()\n",
    "visualize_outputs(sim_outs, map_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda4321",
   "metadata": {
    "id": "DjpS1pIZJ0B-"
   },
   "source": [
    "## Calculate the performance metrics from the episode outputs\n",
    "\n",
    "We can also calculate the various quantitative metrics on the rolled out episode output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318891b-41ea-415d-8521-fb9eb483c2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ades = []\n",
    "fdes = []\n",
    "table = None\n",
    "def quantify_outputs(sim_outs, metric_set=None):\n",
    "    global table\n",
    "    metric_set = metric_set if metric_set is not None else L2DisplacementYawMetricSet()\n",
    "\n",
    "    metric_set.evaluate(sim_outs)\n",
    "    scene_results = metric_set.evaluator.scene_metric_results\n",
    "    # fields = [\"scene_id\", \"FDE\", \"ADE\"]\n",
    "    # table = PrettyTable(field_names=fields)\n",
    "    tot_fde = 0.0\n",
    "    tot_ade = 0.0\n",
    "    # ades = []\n",
    "    # fdes = []\n",
    "    for scene_id in scene_results:\n",
    "        scene_metrics = scene_results[scene_id]\n",
    "        ade_error = scene_metrics[\"displacement_error_l2\"][1:].mean()\n",
    "        fde_error = scene_metrics['displacement_error_l2'][-1]\n",
    "        # table.add_row([scene_id, round(fde_error.item(), 4), round(ade_error.item(), 4)])\n",
    "        ades.append(ade_error.item())\n",
    "        fdes.append(fde_error.item())\n",
    "        # tot_fde += fde_error.item()\n",
    "        # tot_ade += ade_error.item()\n",
    "    # ave_fde = tot_fde / len(scene_results)\n",
    "    # ave_ade = tot_ade / len(scene_results)\n",
    "#     table.add_row([\"Overall\", round(ave_fde, 4) + , round(ave_ade, 4)])\n",
    "    \n",
    "    # print(table)\n",
    "\n",
    "\n",
    "\n",
    "quantify_outputs(sim_outs)\n",
    "# table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba684429-d1a7-4bfe-b13a-72748820a76d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(round(np.mean(ades),2), round((np.std(ades)),2) ,round((np.max(ades) - np.min(ades))/2,2))\n",
    "print(round(np.mean(fdes),2), round((np.std(fdes)),2) ,round((np.max(fdes) - np.min(fdes))/2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86998f20-e766-4753-ad6d-4cffd1b283f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "sorted_ades_idx = sorted(range(len(ades)), key=lambda i: ades[i], reverse=True)\n",
    "sorted_fdes_idx = sorted(range(len(fdes)), key=lambda i: fdes[i], reverse=True)\n",
    "# sorted(range(len(ades)), key=lambda i: ades[i])[-10:]\n",
    "print(f'Top worst scence based on ade:{sorted_ades_idx[:10]}')\n",
    "print(f'Top best scence based on ade:{sorted_ades_idx[:-10:-1]}')\n",
    "print(f'Top worst scence based on fde:{sorted_fdes_idx[:10]}')\n",
    "print(f'Top best scence based on fde:{sorted_fdes_idx[:-10:-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab675c5-cbe5-493b-ad35-8569edfc1501",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Best ade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ddcc9-b816-46c8-bc91-909ca190e415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# might change with different rasterizer\n",
    "map_API = rollout_env.dataset.rasterizer.sem_rast.mapAPI\n",
    "sim_outs_selected = [sim_outs[i] for i in sorted_ades_idx[-10:-1]]\n",
    "visualize_outputs(sim_outs_selected, map_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ab7e1-e510-4609-b837-6bacfa646e62",
   "metadata": {},
   "source": [
    "### Worst ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2caa451-10e9-4042-8ac7-0dac1d9e1633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# might change with different rasterizer\n",
    "map_API = rollout_env.dataset.rasterizer.sem_rast.mapAPI\n",
    "sim_outs_selected = [sim_outs[i] for i in sorted_ades_idx[:10]]\n",
    "visualize_outputs(sim_outs_selected, map_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa210d82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6M1kUv8_J3X7",
    "outputId": "5eba9295-94de-404d-9469-329856bd9384",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantify_outputs(sim_outs, metric_set=None):\n",
    "    metric_set = metric_set if metric_set is not None else L2DisplacementYawMetricSet()\n",
    "\n",
    "    metric_set.evaluate(sim_outs)\n",
    "    scene_results = metric_set.evaluator.scene_metric_results\n",
    "    fields = [\"scene_id\", \"FDE\", \"ADE\"]\n",
    "    table = PrettyTable(field_names=fields)\n",
    "    tot_fde = 0.0\n",
    "    tot_ade = 0.0\n",
    "    for scene_id in scene_results:\n",
    "        scene_metrics = scene_results[scene_id]\n",
    "        ade_error = scene_metrics[\"displacement_error_l2\"][1:].mean()\n",
    "        fde_error = scene_metrics['displacement_error_l2'][-1]\n",
    "        table.add_row([scene_id, round(fde_error.item(), 4), round(ade_error.item(), 4)])\n",
    "        tot_fde += fde_error.item()\n",
    "        tot_ade += ade_error.item()\n",
    "\n",
    "    ave_fde = tot_fde / len(scene_results)\n",
    "    ave_ade = tot_ade / len(scene_results)\n",
    "    table.add_row([\"Overall\", round(ave_fde, 4), round(ave_ade, 4)])\n",
    "    print(table)\n",
    "\n",
    "quantify_outputs(sim_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ebaac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovwnSl6RJx7t",
    "outputId": "972861d0-0929-43ea-ece0-c12cb9698ebd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantify_outputs(sim_outs, metric_set=None):\n",
    "    metric_set = metric_set if metric_set is not None else CLEMetricSet()\n",
    "\n",
    "    metric_set.evaluate(sim_outs)\n",
    "    scene_results = metric_set.evaluator.scene_metric_results\n",
    "    fields = [\"scene_id\", \"FDE\", \"ADE\", \"DRT\", \"CF\", \"CR\", \"CS\", \"PEGO\"]\n",
    "    table = PrettyTable(field_names=fields)\n",
    "    tot_fde = 0.0\n",
    "    tot_ade = 0.0\n",
    "    tot_drt = 0.0\n",
    "    tot_cf = 0.0\n",
    "    tot_cr = 0.0\n",
    "    tot_cs = 0.0\n",
    "    tot_p_ego = 0.0\n",
    "    tot_a_ego = 0.0\n",
    "    # print(scene_results[0])\n",
    "    for scene_id in scene_results:\n",
    "        scene_metrics = scene_results[scene_id]\n",
    "        ade_error = scene_metrics[\"displacement_error_l2\"][1:].mean()\n",
    "        fde_error = scene_metrics['displacement_error_l2'][-1]\n",
    "        drt_error = scene_metrics['distance_to_reference_trajectory'][-1]\n",
    "        cf_error = scene_metrics['collision_front'][-1]\n",
    "        cr_error = scene_metrics['collision_rear'][-1]\n",
    "        cs_error = scene_metrics['collision_side'][-1]\n",
    "        p_ego = scene_metrics['simulated_minus_recorded_ego_speed'][-1]\n",
    "        # a_ego = scene_metrics['aggressive_ego'][-1]\n",
    "        table.add_row([scene_id, round(fde_error.item(), 4), round(ade_error.item(), 4), round(drt_error.item(), 4), round(cf_error.item(), 4), round(cr_error.item(), 4), \n",
    "        round(cs_error.item(), 4), round(p_ego.item(), 4)])\n",
    "        tot_fde += fde_error.item()\n",
    "        tot_ade += ade_error.item()\n",
    "        tot_drt += drt_error.item()\n",
    "        tot_cf += cf_error.item()\n",
    "        tot_cr += cr_error.item()\n",
    "        tot_cs += cs_error.item()\n",
    "        tot_p_ego += p_ego.item()\n",
    "        # tot_a_ego += a_ego.item()\n",
    "\n",
    "    ave_fde = tot_fde / len(scene_results)\n",
    "    ave_ade = tot_ade / len(scene_results)\n",
    "    ave_drt = tot_drt / len(scene_results)\n",
    "    ave_cf = tot_cf / len(scene_results)\n",
    "    ave_cr = tot_cr / len(scene_results)\n",
    "    ave_cs = tot_cs / len(scene_results)\n",
    "    ave_p_ego = tot_p_ego / len(scene_results)\n",
    "    # ave_a_ego = tot_a_ego / len(scene_results)\n",
    "    table.add_row([\"Overall\", round(ave_fde, 4), round(ave_ade, 4), round(ave_drt, 4), round(ave_cf, 4), round(ave_cr, 4), round(ave_cs, 4), round(ave_p_ego, 4)])\n",
    "    print(table)\n",
    "\n",
    "\n",
    "quantify_outputs(sim_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269453ca-efe0-4ed5-8c05-db5f2f136d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Fag3VuhPnRZT",
    "xHfH5HGWoTD7",
    "eBwt9neMoj9h",
    "0CAZm9UDo1C0"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6df7c2a3d813445d6b3c74a479f8d37af444dbb4628cead36b7b0d6872de20bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
