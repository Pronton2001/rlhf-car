{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "210e786a",
   "metadata": {
    "id": "f7f64953"
   },
   "source": [
    "### Training RL Policies using L5Kit Closed-Loop Environment\n",
    "\n",
    "This notebook describes how to train RL policies for self-driving using our gym-compatible closed-loop environment.\n",
    "\n",
    "We will be using [Proximal Policy Optimization (PPO)](https://arxiv.org/abs/1707.06347) algorithm as our reinforcement learning algorithm, as it not only demonstrates remarkable performance but it is also empirically easy to tune.\n",
    "\n",
    "The PPO implementation in this notebook is based on [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3) framework, a popular framework for training RL policies. Note that our environment is also compatible with [RLlib](https://docs.ray.io/en/latest/rllib.html), another popular frameworks for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20eb9fd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smZ0MKsHE2_s",
    "outputId": "beec8a76-eca3-467b-ddd7-5c529d843581",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = '/workspace/datasets'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f47de7",
   "metadata": {
    "id": "806093d7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #@title Download L5 Sample Dataset and install L5Kit\n",
    "# import os\n",
    "# RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "# if RunningInCOLAB:\n",
    "#     !wget https://raw.githubusercontent.com/lyft/l5kit/master/examples/setup_notebook_colab.sh -q\n",
    "#     !sh ./setup_notebook_colab.sh\n",
    "#     os.environ[\"L5KIT_DATA_FOLDER\"] = open(\"./dataset_dir.txt\", \"r\").read().strip()\n",
    "# else:\n",
    "#     os.environ[\"L5KIT_DATA_FOLDER\"] = \"/tmp/level5_data\"\n",
    "#     print(\"Not running in Google Colab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b5492d",
   "metadata": {
    "id": "585b1fe7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import get_linear_fn\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.environment.feature_extractor import CustomFeatureExtractor\n",
    "from l5kit.environment.callbacks import L5KitEvalCallback\n",
    "from l5kit.environment.envs.l5_env import SimulationConfigGym\n",
    "\n",
    "from l5kit.visualization.visualizer.zarr_utils import episode_out_to_visualizer_scene_gym_cle\n",
    "from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from bokeh.io import output_notebook, show\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1560a235",
   "metadata": {
    "id": "2ea81f77",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset is assumed to be on the folder specified\n",
    "# in the L5KIT_DATA_FOLDER environment variable\n",
    "\n",
    "# get environment config\n",
    "env_config_path = '/workspace/source/configs/gym_config.yaml'\n",
    "cfg = load_config_data(env_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6372301",
   "metadata": {
    "id": "2cead394"
   },
   "source": [
    "### Define Training and Evaluation Environments\n",
    "\n",
    "**Training**: We will be training the PPO policy on episodes of length 32 time-steps. We will have 4 sub-processes (training environments) that will help to parallelize and speeden up episode rollouts. The *SimConfig* dataclass will define the parameters of the episode rollout: like length of episode rollout, whether to use log-replayed agents or simulated agents etc.\n",
    "\n",
    "**Evaluation**: We will evaluate the performance of the PPO policy on the *entire* scene (~248 time-steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e30d5e9",
   "metadata": {
    "id": "b04c8313",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/source/l5kit_original1/l5kit/l5kit/data/zarr_dataset.py:213: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit_original1/l5kit/l5kit/data/zarr_dataset.py:213: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit_original1/l5kit/l5kit/simulation/utils.py:107: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  new_dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit_original1/l5kit/l5kit/data/zarr_dataset.py:213: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit_original1/l5kit/l5kit/data/zarr_dataset.py:213: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit_original1/l5kit/l5kit/simulation/utils.py:107: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  new_dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit_original1/l5kit/l5kit/simulation/utils.py:107: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  new_dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit_original1/l5kit/l5kit/simulation/utils.py:107: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  new_dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit_original1/l5kit/l5kit/data/zarr_dataset.py:213: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit_original1/l5kit/l5kit/simulation/utils.py:107: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  new_dataset = ChunkedDataset(\"\")\n"
     ]
    }
   ],
   "source": [
    "# Train on episodes of length 32 time steps\n",
    "train_eps_length = 32\n",
    "train_envs = 4\n",
    "\n",
    "# Evaluate on entire scene (~248 time steps)\n",
    "eval_eps_length = None\n",
    "eval_envs = 1\n",
    "\n",
    "# make train env\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "env = make_vec_env(\"L5-CLE-v0\", env_kwargs=env_kwargs, n_envs=train_envs,\n",
    "                   vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"fork\"})\n",
    "\n",
    "# make eval env\n",
    "validation_sim_cfg = SimulationConfigGym()\n",
    "validation_sim_cfg.num_simulation_steps = None\n",
    "eval_env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, \\\n",
    "                   'return_info': True, 'train': False, 'sim_cfg': validation_sim_cfg}\n",
    "eval_env = make_vec_env(\"L5-CLE-v0\", env_kwargs=eval_env_kwargs, n_envs=eval_envs,\n",
    "                        vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"fork\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a222c",
   "metadata": {
    "id": "9dfc8b1a"
   },
   "source": [
    "### Define backbone feature extractor\n",
    "\n",
    "The backbone feature extractor is shared between the policy and the value networks. The feature extractor *simple_gn* is composed of two convolutional networks followed by a fully connected layer, with ReLU activation. The feature extractor output is passed to both the policy and value networks composed of two fully connected layers with tanh activation (SB3 default).\n",
    "\n",
    "We perform **group normalization** after every convolutional layer. Empirically, we found that group normalization performs far superior to batch normalization. This can be attributed to the fact that activation statistics change quickly in on-policy algorithms (PPO is on-policy) while batch-norm learnable parameters can be slow to update causing training issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fabc3f",
   "metadata": {
    "id": "4da5ac39",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A simple 2 Layer CNN architecture with group normalization\n",
    "model_arch = 'simple_gn'\n",
    "features_dim = 128\n",
    "\n",
    "# Custom Feature Extractor backbone\n",
    "policy_kwargs = {\n",
    "    \"features_extractor_class\": CustomFeatureExtractor,\n",
    "    \"features_extractor_kwargs\": {\"features_dim\": features_dim, \"model_arch\": model_arch},\n",
    "    \"normalize_images\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d40b9a2",
   "metadata": {
    "id": "24ec4f23"
   },
   "source": [
    "### Clipping Schedule\n",
    "\n",
    "We linearly decrease the value of the clipping parameter $\\epsilon$ as the PPO training progress as it shows improved training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "452ab555",
   "metadata": {
    "id": "dc28b605",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clipping schedule of PPO epsilon parameter\n",
    "start_val = 0.1\n",
    "end_val = 0.01\n",
    "training_progress_ratio = 1.0\n",
    "clip_schedule = get_linear_fn(start_val, end_val, training_progress_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0da86",
   "metadata": {
    "id": "8596deb6"
   },
   "source": [
    "### Hyperparameters for PPO. \n",
    "\n",
    "For detailed description, refer https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/ppo/ppo.html#PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8442a40d",
   "metadata": {
    "id": "998a927f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "num_rollout_steps =  256 #2048#\n",
    "gamma = 0.8\n",
    "gae_lambda = 0.9\n",
    "n_epochs = 10 #16 #10\n",
    "seed = 42\n",
    "batch_size =  64 #512 #\n",
    "tensorboard_log = '/workspace/datasets/sb3_tb_logs/' + str(datetime.date.today()) + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc28001-a6b6-43b8-b7fe-120812e4f835",
   "metadata": {},
   "source": [
    "### For debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bfe48ef-6e47-4c50-8539-b8f7444161c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "num_rollout_steps =  1 #2048#\n",
    "gamma = 0.8\n",
    "gae_lambda = 0.9\n",
    "n_epochs = 1 #16 #10\n",
    "seed = 42\n",
    "batch_size =  2 #512 #\n",
    "tensorboard_log = '/workspace/datasets/sb3_tb_logs/' + str(datetime.date.today()) + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b672e2d4",
   "metadata": {
    "id": "a310190e",
    "tags": []
   },
   "source": [
    "### Define the PPO Policy.\n",
    "\n",
    "SB3 provides an easy interface to the define the PPO policy. Note: We do need to tweak appropriate hyperparameters and the custom policy backbone has been defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f67a10b-93a5-4d04-b90d-c2b44d152400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff6a09c1-fd93-40e2-acd3-c0f9144bc669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'ppo_policy_training.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75cac60e-3285-4fee-8961-b444c0a30f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr' : 3e-4,\n",
    "    'num_rollout_steps' :  256, # 2048\n",
    "    'gamma' : 0.8,\n",
    "    'gae_lambda' : 0.9,\n",
    "    'n_epochs' : 10, # 16, #10\n",
    "    'seed' : 42,\n",
    "    'batch_size' : 64, # 512\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e90d5fb3-dab6-40b2-b346-c9e885523de6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ppo_policy_training.ipynb.\n",
      "2023-03-31 03:20:15.717919: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 03:20:15.797839: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-31 03:20:16.222021: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-31 03:20:16.222058: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-31 03:20:16.222062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpronton2001\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/source/wandb/run-20230331_032017-1h2g87af</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pronton2001/l5kit2/runs/1h2g87af' target=\"_blank\">PPO_sb3_31-03-2023_10-20-15</a></strong> to <a href='https://wandb.ai/pronton2001/l5kit2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pronton2001/l5kit2' target=\"_blank\">https://wandb.ai/pronton2001/l5kit2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pronton2001/l5kit2/runs/1h2g87af' target=\"_blank\">https://wandb.ai/pronton2001/l5kit2/runs/1h2g87af</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hcmTz = pytz.timezone(\"Asia/Ho_Chi_Minh\") \n",
    "date = datetime.datetime.now(hcmTz).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "\n",
    "experiment_name = f\"PPO_sb3_{date}\"\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"l5kit2\",\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    monitor_gym=False,  # auto-upload the videos of agents playing the game\n",
    "    save_code=True,  # optional\n",
    "    reinit = True,\n",
    "    group = 'PPO',\n",
    "    config = config,\n",
    "    name = experiment_name\n",
    "    # name = 'PPO_sb3_05-01-2023_15-12-56(3)',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "758dcefe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d474019b",
    "outputId": "eedbc005-9fc7-4f32-88b7-7718881f9356",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=0, n_steps=num_rollout_steps,\n",
    "            learning_rate=lr, gamma=gamma, tensorboard_log=f\"runs/{run.id}\", n_epochs=n_epochs,\n",
    "            clip_range=clip_schedule, batch_size=batch_size, seed=seed, gae_lambda=gae_lambda,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c376ed1-a226-4f63-ab10-81ac46ec7ed3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f460a-8640-44d0-b78f-e5fee3c7a5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=0, n_steps=num_rollout_steps,\n",
    "            learning_rate=lr, gamma=gamma, tensorboard_log=tensorboard_log, n_epochs=n_epochs,\n",
    "            clip_range=clip_schedule, batch_size=batch_size, seed=seed, gae_lambda=gae_lambda,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea92e6f5",
   "metadata": {
    "id": "53754180",
    "tags": []
   },
   "source": [
    "### Defining Callbacks\n",
    "\n",
    "We can additionally define callbacks to save model checkpoints and evaluate models during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b21fdba5",
   "metadata": {
    "id": "f19803ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback_list = []\n",
    "hcmTz = pytz.timezone(\"Asia/Ho_Chi_Minh\") \n",
    "date = datetime.datetime.now(hcmTz).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "# Save Model Periodically\n",
    "save_freq = 10000\n",
    "save_path = '/workspace/datasets/sb3_results/'+ date\n",
    "# save_path = 'l5kit/logs/05-01-2023_15-12-56'\n",
    "output = 'PPO'\n",
    "checkpoint_callback = CheckpointCallback(save_freq=(save_freq // train_envs), save_path=save_path, \\\n",
    "                                         name_prefix=output)\n",
    "callback_list.append(checkpoint_callback)\n",
    "\n",
    "# Eval Model Periodically\n",
    "eval_freq = 10000\n",
    "n_eval_episodes = 1\n",
    "val_eval_callback = L5KitEvalCallback(eval_env, eval_freq=(eval_freq // train_envs), \\\n",
    "                                      n_eval_episodes=n_eval_episodes, n_eval_envs=eval_envs)\n",
    "callback_list.append(val_eval_callback)\n",
    "callback_list.append(WandbCallback(\n",
    "        gradient_save_freq=100,\n",
    "        model_save_path=f\"models/{run.id}\",\n",
    "        verbose=2,\n",
    "        model_save_freq=10,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f6d8b",
   "metadata": {
    "id": "ad3bda21",
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918f085",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Rcvlddp8ppQ",
    "outputId": "a13d3561-e14f-4cd4-a236-72b11d9bddd4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_steps = 6e6\n",
    "\n",
    "model.learn(n_steps, callback=callback_list)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134bd79",
   "metadata": {
    "id": "575327a2"
   },
   "source": [
    "**Voila!** We have a trained PPO policy! Train for larger number of steps for better accuracy. Typical RL algorithms require training atleast 1M steps for good convergence. You can visualize the quantitiative evaluation using tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3807ba",
   "metadata": {
    "id": "CFi-_Iioi_Z7"
   },
   "outputs": [],
   "source": [
    "model = PPO.load('/content/drive/MyDrive/Colab Notebooks/l5kit/logs/2022-11-30/PPO_5410000_steps.zip', env = env, batch_size=512)\n",
    "n_steps = 6e6\n",
    "# model = PPO.load('./PPO_100000_steps.zip', env = env)\n",
    "model.learn(n_steps, callback=callback_list, reset_num_timesteps=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb10ca5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xk03paZgWMop",
    "outputId": "29a9b7eb-bced-4763-cf88-9ee59e9884b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/l5kit-SbltAjJJ/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from '/root/.local/share/virtualenvs/l5kit-SbltAjJJ/lib/python3.8/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "/root/.local/share/virtualenvs/l5kit-SbltAjJJ/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from '/root/.local/share/virtualenvs/l5kit-SbltAjJJ/lib/python3.8/site-packages/cloudpickle/cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "/root/.local/share/virtualenvs/l5kit-SbltAjJJ/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:719: UserWarning: You are probably loading a model saved with SB3 < 1.7.0, we deactivated exact_match so you can save the model again to avoid issues in the future (see https://github.com/DLR-RM/stable-baselines3/issues/1233 for more info). Original error: Error(s) in loading state_dict for MultiInputActorCriticPolicy:\n",
      "\tMissing key(s) in state_dict: \"pi_features_extractor.extractors.image.0.weight\", \"pi_features_extractor.extractors.image.1.weight\", \"pi_features_extractor.extractors.image.1.bias\", \"pi_features_extractor.extractors.image.4.weight\", \"pi_features_extractor.extractors.image.5.weight\", \"pi_features_extractor.extractors.image.5.bias\", \"pi_features_extractor.extractors.image.9.weight\", \"pi_features_extractor.extractors.image.9.bias\", \"vf_features_extractor.extractors.image.0.weight\", \"vf_features_extractor.extractors.image.1.weight\", \"vf_features_extractor.extractors.image.1.bias\", \"vf_features_extractor.extractors.image.4.weight\", \"vf_features_extractor.extractors.image.5.weight\", \"vf_features_extractor.extractors.image.5.bias\", \"vf_features_extractor.extractors.image.9.weight\", \"vf_features_extractor.extractors.image.9.bias\".  \n",
      "Note: the model should still work fine, this only a warning.\n",
      "  warnings.warn(\n",
      "2023-03-31 03:21:05.107532: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 03:21:05.189055: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-31 03:21:05.660281: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-31 03:21:05.660326: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-31 03:21:05.660330: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/virtualenvs/l5kit-SbltAjJJ/lib/python3.8/site-packages/wandb/filesync/step_checksum.py\", line 82, in _thread_body\n",
      "    shutil.copy2(req.path, path)\n",
      "  File \"/usr/lib/python3.8/shutil.py\", line 435, in copy2\n",
      "    copyfile(src, dst, follow_symlinks=follow_symlinks)\n",
      "  File \"/usr/lib/python3.8/shutil.py\", line 275, in copyfile\n",
      "    _fastcopy_sendfile(fsrc, fdst)\n",
      "  File \"/usr/lib/python3.8/shutil.py\", line 166, in _fastcopy_sendfile\n",
      "    raise err from None\n",
      "  File \"/usr/lib/python3.8/shutil.py\", line 152, in _fastcopy_sendfile\n",
      "    sent = os.sendfile(outfd, infd, offset, blocksize)\n",
      "OSError: [Errno 28] No space left on device: '/workspace/source/wandb/run-20230331_032017-1h2g87af/files/model.zip' -> '/tmp/tmpo31ws05swandb/i5x3ztlu-model.zip'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.local/share/virtualenvs/l5kit-SbltAjJJ/lib/python3.8/site-packages/wandb/filesync/step_checksum.py\", line 85, in _thread_body\n",
      "    shutil.copy2(req.path, path)\n",
      "  File \"/usr/lib/python3.8/shutil.py\", line 435, in copy2\n",
      "    copyfile(src, dst, follow_symlinks=follow_symlinks)\n",
      "  File \"/usr/lib/python3.8/shutil.py\", line 285, in copyfile\n",
      "    copyfileobj(fsrc, fdst)\n",
      "  File \"/usr/lib/python3.8/shutil.py\", line 208, in copyfileobj\n",
      "    fdst_write(buf)\n",
      "OSError: [Errno 28] No space left on device\n"
     ]
    }
   ],
   "source": [
    "# model = PPO.load('l5kit/logs/05-01-2023_15-12-56/PPO_9790000_steps.zip', env = env)\n",
    "model = PPO.load('/workspace/datasets/sb3_results/23-03-2023_14-51-50/PPO_1850000_steps.zip', env = env)\n",
    "\n",
    "n_steps = 6e6\n",
    "# model = PPO.load('./PPO_100000_steps.zip', env = env)\n",
    "model.learn(n_steps, callback=callback_list, reset_num_timesteps=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c50b644",
   "metadata": {
    "id": "d24f956c",
    "tags": []
   },
   "source": [
    "### Visualize the episode from the environment\n",
    "\n",
    "We can easily visualize the outputs obtained by rolling out episodes in the L5Kit using the Bokeh visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393652f7",
   "metadata": {
    "id": "UCLaP7ZVtKPO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/l5kit-ZbMednhg/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:719: UserWarning: You are probably loading a model saved with SB3 < 1.7.0, we deactivated exact_match so you can save the model again to avoid issues in the future (see https://github.com/DLR-RM/stable-baselines3/issues/1233 for more info). Original error: Error(s) in loading state_dict for MultiInputActorCriticPolicy:\n",
      "\tMissing key(s) in state_dict: \"pi_features_extractor.extractors.image.0.weight\", \"pi_features_extractor.extractors.image.1.weight\", \"pi_features_extractor.extractors.image.1.bias\", \"pi_features_extractor.extractors.image.4.weight\", \"pi_features_extractor.extractors.image.5.weight\", \"pi_features_extractor.extractors.image.5.bias\", \"pi_features_extractor.extractors.image.9.weight\", \"pi_features_extractor.extractors.image.9.bias\", \"vf_features_extractor.extractors.image.0.weight\", \"vf_features_extractor.extractors.image.1.weight\", \"vf_features_extractor.extractors.image.1.bias\", \"vf_features_extractor.extractors.image.4.weight\", \"vf_features_extractor.extractors.image.5.weight\", \"vf_features_extractor.extractors.image.5.bias\", \"vf_features_extractor.extractors.image.9.weight\", \"vf_features_extractor.extractors.image.9.bias\".  \n",
      "Note: the model should still work fine, this only a warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model = PPO.load('l5kit/logs/05-01-2023_15-12-56/PPO_6000000_steps.zip', env = env)\n",
    "model = PPO.load('/workspace/datasets/logs/05-01-2023_15-12-56/PPO_15790000_steps.zip', env = env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "929a8efd",
   "metadata": {
    "id": "-bp59EHAywuW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PPO.load('/workspace/datasets/logs/05-01-2023_15-12-56/PPO_15790000_steps.zip', env = env,  custom_objects = {\n",
    "      \"learning_rate\": 0.0,\n",
    "      \"lr_schedule\": lambda _: 0.0,\n",
    "      \"clip_range\": lambda _: 0.0,\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "565c2c34",
   "metadata": {
    "id": "fcd2b424"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/source/l5kit2/l5kit/l5kit/data/zarr_dataset.py:213: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  dataset = ChunkedDataset(\"\")\n",
      "/workspace/source/l5kit2/l5kit/l5kit/simulation/utils.py:107: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  new_dataset = ChunkedDataset(\"\")\n"
     ]
    }
   ],
   "source": [
    "rollout_sim_cfg = SimulationConfigGym()\n",
    "rollout_sim_cfg.num_simulation_steps = None\n",
    "rollout_env = gym.make(\"L5-CLE-v0\", env_config_path=env_config_path, sim_cfg=rollout_sim_cfg, \\\n",
    "                       use_kinematic=True, train=False, return_info=True)\n",
    "\n",
    "from src.simulation.unrollGym import unroll\n",
    "sim_outs = unroll(model, rollout_env,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53c513",
   "metadata": {
    "id": "DjpS1pIZJ0B-",
    "tags": []
   },
   "source": [
    "## Calculate the performance metrics from the episode outputs\n",
    "\n",
    "We can also calculate the various quantitative metrics on the rolled out episode output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8293c8-8d42-4860-bd36-7a2df9c50586",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim_outs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2050603/3241597600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_ade_fde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantify_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mades\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_ade_fde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mquantify_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sim_outs' is not defined"
     ]
    }
   ],
   "source": [
    "from src.validate.validator import compute_ade_fde, quantify_outputs\n",
    "ades, fdes = compute_ade_fde(sim_outs)\n",
    "quantify_outputs(sim_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "488f2431-e2f2-436f-a1b1-4d27b0a12f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.99 25.06 52.84\n",
      "60.62 63.78 127.85\n",
      "Top worst scence based on ade:[55, 32, 72, 70, 3, 33, 76, 35, 79, 43]\n",
      "Top best scence based on ade:[15, 37, 67, 50, 51, 49, 66, 52, 48]\n",
      "Top worst scence based on fde:[55, 32, 79, 43, 35, 72, 70, 4, 11, 33]\n",
      "Top best scence based on fde:[37, 15, 36, 90, 51, 49, 52, 48, 50]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(round(np.mean(ades),2), round((np.std(ades)),2) ,round((np.max(ades) - np.min(ades))/2,2))\n",
    "print(round(np.mean(fdes),2), round((np.std(fdes)),2) ,round((np.max(fdes) - np.min(fdes))/2,2))\n",
    "sorted_ades_idx = sorted(range(len(ades)), key=lambda i: ades[i], reverse=True)\n",
    "sorted_fdes_idx = sorted(range(len(fdes)), key=lambda i: fdes[i], reverse=True)\n",
    "# sorted(range(len(ades)), key=lambda i: ades[i])[-10:]\n",
    "print(f'Top worst scence based on ade:{sorted_ades_idx[:10]}')\n",
    "print(f'Top best scence based on ade:{sorted_ades_idx[:-10:-1]}')\n",
    "print(f'Top worst scence based on fde:{sorted_fdes_idx[:10]}')\n",
    "print(f'Top best scence based on fde:{sorted_fdes_idx[:-10:-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787e996-78c7-43d4-855c-b86f346e8ba2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Best ade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27ee55-5582-4efb-9ed4-f310197e9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might change with different rasterizer\n",
    "sim_outs_selected =  [sim_outs[i] for i in sorted_ades_idx[-5:-1]]\n",
    "output_notebook()\n",
    "visualize_outputs(sim_outs_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a9efb-c130-406c-a822-31289c6a0263",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Worst ade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d78446-aeac-4358-8d15-af2bb7890bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might change with different rasterizer\n",
    "sim_outs_selected =  [sim_outs[i] for i in sorted_ades_idx[:5]]\n",
    "output_notebook()\n",
    "visualize_outputs(sim_outs_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df538f-aef4-489a-bfba-61f4bc1971fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e0e2897-c7f7-44c0-b403-61db058e3b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------+\n",
      "|          metric         | value |\n",
      "+-------------------------+-------+\n",
      "|  displacement_error_l2  |   5   |\n",
      "| distance_ref_trajectory |   30  |\n",
      "|     collision_front     |   6   |\n",
      "|      collision_rear     |   22  |\n",
      "|      collision_side     |   16  |\n",
      "+-------------------------+-------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.validate.validator import CLEValidator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "agg = CLEValidator(sim_outs)\n",
    "fields = [\"metric\", \"value\"]\n",
    "table = PrettyTable(field_names=fields)\n",
    "\n",
    "values = []\n",
    "names = []\n",
    "\n",
    "for metric_name in agg:\n",
    "    table.add_row([metric_name, agg[metric_name].item()])\n",
    "    values.append(agg[metric_name].item())\n",
    "    names.append(metric_name)\n",
    "\n",
    "print(table)\n",
    "\n",
    "plt.bar(np.arange(len(names)), values)\n",
    "plt.xticks(np.arange(len(names)), names, rotation=60, ha='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6df7c2a3d813445d6b3c74a479f8d37af444dbb4628cead36b7b0d6872de20bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
