{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.customModel.customModel import TorchAttentionModel3, TorchAttentionModel4\n",
    "\n",
    "from src.constant import SRC_PATH\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = '/workspace/datasets'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']= '0'\n",
    "# os.environ[\"TUNE_RESULT_DIR\"] =  '/DATA/l5kit/rllib_tb_logs'\n",
    "import gym\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.environment.envs.l5_env import SimulationConfigGym, GymStepOutput, L5Env\n",
    "from l5kit.environment.envs.l5_env2 import SimulationConfigGym, GymStepOutput, L5Env2\n",
    "from l5kit.visualization.visualizer.zarr_utils import episode_out_to_visualizer_scene_gym_cle\n",
    "from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from bokeh.io import output_notebook, show\n",
    "from l5kit.environment.gym_metric_set import L2DisplacementYawMetricSet, CLEMetricSet\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gym\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import ray\n",
    "import pytz\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 07:22:35,584\tWARNING services.py:1732 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67039232 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=5.12gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-04-22 07:22:36,641\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_cpus=9, ignore_reinit_error=True, log_to_driver=False, object_store_memory = 5*10**9, local_mode=False)\n",
    "\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "\n",
    "env_config_path = SRC_PATH + 'src/configs/gym_vectorizer_config.yaml'\n",
    "env_config_path = SRC_PATH + 'src/configs/gym_vectorizer_config_hist3.yaml'\n",
    "cfg = load_config_data(env_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from src.customEnv.wrapper import L5EnvWrapper, L5EnvWrapperTorch\n",
    "train_eps_length = 32\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "\n",
    "tune.register_env(\"L5-CLE-V2\", lambda config: L5Env2(**env_kwargs))\n",
    "ModelCatalog.register_custom_model( \"TorchAttentionModel3\", TorchAttentionModel3)\n",
    "ModelCatalog.register_custom_model( \"TorchAttentionModel4\", TorchAttentionModel4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "hcmTz = pytz.timezone(\"Asia/Ho_Chi_Minh\") \n",
    "date = datetime.datetime.now(hcmTz).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "ray_result_logdir = '/home/pronton/ray_results/debug_vector_ppo_separated_kin_hist3' + date\n",
    "\n",
    "train_envs = 4\n",
    "lr = 3e-4\n",
    "lr_start = 3e-5\n",
    "lr_end = 3e-6\n",
    "lr_time = int(4e6)\n",
    "\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V2\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 8,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    \"model\": {\n",
    "        \"custom_model\": \"TorchAttentionModel4\",\n",
    "        \"custom_model_config\": {'cfg':cfg,\n",
    "                                'freeze_actor': False,\n",
    "                                'shared_feature_extractor': False,\n",
    "                                },\n",
    "    },\n",
    "    \n",
    "    # 'model' : {\n",
    "    #         # \"dim\": 84,\n",
    "    #         # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "    #         # \"conv_activation\": \"relu\",\n",
    "    #         \"post_fcnet_hiddens\": [256],\n",
    "    #         \"post_fcnet_activation\": \"relu\",\n",
    "    #         \"vf_share_layers\": False,   \n",
    "    # },\n",
    "    \n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    "    \"lr\": lr,\n",
    "    'seed': 42,\n",
    "    \"lr_schedule\": [\n",
    "        [7e5, lr_start],\n",
    "        [2e6, lr_end],\n",
    "    ],\n",
    "    'train_batch_size': 1024, # 8000 \n",
    "    'sgd_minibatch_size': 512, #2048\n",
    "    'num_sgd_iter': 10,#16,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    # \"rollout_fragment_length\": 32,\n",
    "    'gamma': 0.8,    \n",
    "}\n",
    "\n",
    "result_grid = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 0, 'timesteps_total': int(6e6)},\n",
    "        local_dir=ray_result_logdir,\n",
    "        checkpoint_config=air.CheckpointConfig(num_to_keep=2, \n",
    "                                               checkpoint_frequency = 10, \n",
    "                                               checkpoint_score_attribute = 'episode_reward_mean'),\n",
    "        # callbacks=[WandbLoggerCallback(project=\"l5kit2\", save_code = True, save_checkpoints = False),],\n",
    "        ),\n",
    "    param_space=config_param_space).fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_envs = 4\n",
    "lr = 3e-4\n",
    "lr_start = 3e-5\n",
    "lr_end = 3e-6\n",
    "lr_time = int(4e6)\n",
    "\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V2\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 0,\n",
    "    \"num_workers\": 8,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    \"model\": {\n",
    "        \"custom_model\": \"TorchAttentionModel4\",\n",
    "        \"custom_model_config\": {'cfg':cfg,\n",
    "                                'freeze_actor': False,\n",
    "                                'shared_feature_extractor': False,\n",
    "                                },\n",
    "    },\n",
    "    \n",
    "    # 'model' : {\n",
    "    #         # \"dim\": 84,\n",
    "    #         # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "    #         # \"conv_activation\": \"relu\",\n",
    "    #         \"post_fcnet_hiddens\": [256],\n",
    "    #         \"post_fcnet_activation\": \"relu\",\n",
    "    #         \"vf_share_layers\": False,   \n",
    "    # },\n",
    "    \n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    "    \"lr\": lr,\n",
    "    'seed': 42,\n",
    "    \"lr_schedule\": [\n",
    "        [7e5, lr_start],\n",
    "        [2e6, lr_end],\n",
    "    ],\n",
    "    'train_batch_size': 1024, # 8000 \n",
    "    'sgd_minibatch_size': 512, #2048\n",
    "    'num_sgd_iter': 10,#16,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    # \"rollout_fragment_length\": 32,\n",
    "    'gamma': 0.8,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "rollout_sim_cfg = SimulationConfigGym()\n",
    "rollout_sim_cfg.num_simulation_steps = None\n",
    "eval_env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg, 'train': False, 'return_info': True}\n",
    "# env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "rollout_env = L5Env2(**eval_env_kwargs)\n",
    "tune.register_env(\"L5-CLE-EVAL-V2\", lambda config: L5Env2(**eval_env_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 07:22:45,848\tWARNING deprecation.py:47 -- DeprecationWarning: `algo = Algorithm(env='L5-CLE-EVAL-V2', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('L5-CLE-EVAL-V2').build()` instead. This will raise an error in the future!\n",
      "2023-04-22 07:22:45,871\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2023-04-22 07:23:10,961\tWARNING catalog.py:637 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!\n",
      "2023-04-22 07:23:11,509\tINFO trainable.py:172 -- Trainable.setup took 25.641 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-04-22 07:23:11,511\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "2023-04-22 07:23:11,522\tWARNING algorithm_config.py:488 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "2023-04-22 07:23:11,706\tINFO trainable.py:790 -- Restored on 172.17.0.2 from checkpoint: /home/pronton/ray_results/debug_vector_ppo_separated_kin_hist322-04-2023_13-05-42/PPO/PPO_L5-CLE-V2_b6ba7_00000_0_2023-04-22_06-05-42/checkpoint_000410\n",
      "2023-04-22 07:23:11,707\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 410, '_timesteps_total': None, '_time_total': 4010.053626537323, '_episodes_total': 13536}\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPO\n",
    "checkpoint_path = '/home/pronton/ray_results/debug_vector_ppo_separated_kin_hist322-04-2023_13-05-42/PPO/PPO_L5-CLE-V2_b6ba7_00000_0_2023-04-22_06-05-42/checkpoint_000410'\n",
    "algo = PPO(config=config_param_space, env='L5-CLE-EVAL-V2')\n",
    "algo.restore(checkpoint_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unroll scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.simulation.unrollGym import unroll\n",
    "sim_outs = unroll(model, rollout_env, 5,cfg['gym_params']['max_val_scene_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might change with different rasterizer\n",
    "map_API = rollout_env.dataset.rasterizer.sem_rast.mapAPI\n",
    "\n",
    "def visualize_outputs(sim_outs, map_API):\n",
    "    for sim_out in sim_outs: # for each scene\n",
    "        vis_in = episode_out_to_visualizer_scene_gym_cle(sim_out, map_API)\n",
    "        # print(vis_in)\n",
    "        # break\n",
    "        show(visualize(sim_out.scene_id, vis_in))\n",
    "\n",
    "output_notebook()\n",
    "# visualize_outputs(sim_outs, map_API)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l5kit-ON4ChoDr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
