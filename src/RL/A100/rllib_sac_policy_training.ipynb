{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430d5435",
   "metadata": {
    "id": "f7f64953"
   },
   "source": [
    "### Training RL Policies using L5Kit Closed-Loop Environment\n",
    "\n",
    "This notebook describes how to train RL policies for self-driving using our gym-compatible closed-loop environment.\n",
    "\n",
    "We will be using [Proximal Policy Optimization (PPO)](https://arxiv.org/abs/1707.06347) algorithm as our reinforcement learning algorithm, as it not only demonstrates remarkable performance but it is also empirically easy to tune.\n",
    "\n",
    "The PPO implementation in this notebook is based on [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3) framework, a popular framework for training RL policies. Note that our environment is also compatible with [RLlib](https://docs.ray.io/en/latest/rllib.html), another popular frameworks for the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5501b1",
   "metadata": {
    "id": "ulK_RDB4e_gx"
   },
   "source": [
    "ref: \n",
    "([rllib] Best workflow to train, save, and test agent #9123\n",
    ")[https://github.com/ray-project/ray/issues/9123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1bbc82f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smZ0MKsHE2_s",
    "outputId": "631f2d2d-38ee-45ba-f658-b7d11c59139b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = '/DATA/l5kit/l5kit-dataset'\n",
    "# os.environ[\"TUNE_RESULT_DIR\"] =  '/DATA/l5kit/rllib_tb_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521ffe0e",
   "metadata": {
    "id": "585b1fe7"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "# from stable_baselines3.common.env_util import make_vec_env\n",
    "# from stable_baselines3.common.utils import get_linear_fn\n",
    "# from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "# from l5kit.environment.feature_extractor import CustomFeatureExtractor\n",
    "# from l5kit.environment.callbacks import L5KitEvalCallback\n",
    "from l5kit.environment.envs.l5_env import SimulationConfigGym, GymStepOutput, L5Env\n",
    "\n",
    "from l5kit.visualization.visualizer.zarr_utils import episode_out_to_visualizer_scene_gym_cle\n",
    "from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from bokeh.io import output_notebook, show\n",
    "from l5kit.environment.gym_metric_set import L2DisplacementYawMetricSet, CLEMetricSet\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gym\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import ray\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8e8a2",
   "metadata": {
    "id": "xHfH5HGWoTD7"
   },
   "source": [
    "## Init ray and env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36f70ad",
   "metadata": {
    "id": "2ea81f77"
   },
   "outputs": [],
   "source": [
    "# Dataset is assumed to be on the folder specified\n",
    "# in the L5KIT_DATA_FOLDER environment variable\n",
    "from l5kit.configs import load_config_data\n",
    "\n",
    "# get environment config\n",
    "env_config_path = '/DATA/l5kit/configs/gym_config84.yaml'\n",
    "cfg = load_config_data(env_config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58e7093-60b8-40d4-be53-6f2091437d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 08:30:22,200\tWARNING services.py:1732 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67018752 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-01-01 08:30:23,356\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.10</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.10', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '172.17.0.2', 'raylet_ip_address': '172.17.0.2', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-01-01_08-30-20_295376_772/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-01-01_08-30-20_295376_772/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-01-01_08-30-20_295376_772', 'metrics_export_port': 55908, 'gcs_address': '172.17.0.2:64418', 'address': '172.17.0.2:64418', 'dashboard_agent_listen_port': 52365, 'node_id': '2f5ed31ed7ee457fa6d8c9fed45a17acc57e4a5cb2dce9a23e49fd9c'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newYorkTz = pytz.timezone(\"Asia/Ho_Chi_Minh\") \n",
    "date = datetime.datetime.now(newYorkTz).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/' + date\n",
    "\n",
    "ray.init(num_cpus=64, ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f59594b",
   "metadata": {
    "id": "eBwt9neMoj9h",
    "tags": []
   },
   "source": [
    "## Customize my model\n",
    "SAC: https://github.com/ray-project/ray/blob/dfb9689701361cfd18f383e0a3edeed6baf81abb/rllib/agents/sac/sac_torch_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9a14aa",
   "metadata": {
    "id": "fs23j_7Som37",
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3054087535.py, line 63)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [6], line 63\u001b[0;36m\u001b[0m\n\u001b[0;31m    def get_policy_output(self, , input_dict, state, seq_lens):\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class GNCNN(SACTorchModel):\n",
    "    \"\"\"\n",
    "    Simple Convolution agent that calculates the required linear output layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        super().__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        # raise ValueError(obs_space.shape)\n",
    "        self._num_objects = obs_space.shape[2] # num_of_channels of input, size x size x channels\n",
    "        self._num_actions = num_outputs\n",
    "        self._feature_dim = model_config[\"custom_model_config\"]['feature_dim']\n",
    "\n",
    "        # linear_flatten = np.prod(obs_space.shape[:2])*64\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(self._num_objects, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            nn.GroupNorm(4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            nn.GroupNorm(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=1568, out_features=self._feature_dim),\n",
    "            # layer_init(nn.Conv2d(self._num_objects, 32, 3, padding=1)),\n",
    "            # nn.ReLU(),\n",
    "            # layer_init(nn.Conv2d(32, 64, 3, padding=1)),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Flatten(),\n",
    "            # layer_init(nn.Linear(linear_flatten, 1024)),\n",
    "            # nn.ReLU(),\n",
    "            # layer_init(nn.Linear(1024, 512)),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self._actor_head = nn.Sequential(\n",
    "            # layer_init(nn.Linear(512, 256), std=0.01),\n",
    "            # nn.ReLU(),\n",
    "            # layer_init(nn.Linear(256, self._num_actions), std=0.01)\n",
    "            nn.Linear(self._feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self._num_actions),\n",
    "        )\n",
    "\n",
    "        self._critic_head = nn.Sequential(\n",
    "            # layer_init(nn.Linear(512, 1), std=0.01)\n",
    "            nn.Linear(self._feature_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs_transformed = input_dict['obs'].permute(0, 3, 1, 2) # 32 x 112 x 112 x 7 [B, size, size, channels]\n",
    "        network_output = self.network(obs_transformed)\n",
    "        value = self._critic_head(network_output)\n",
    "        self._value = value.reshape(-1)\n",
    "        logits = self._actor_head(network_output)\n",
    "        return logits, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return self._value\n",
    "    def get_policy_output(self, , input_dict, state, seq_lens):\n",
    "        return forward()\n",
    "    def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e32c7d",
   "metadata": {
    "id": "j1cg5X5TotDS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.rllib.models import ModelCatalog\n",
    "ModelCatalog.register_custom_model(\n",
    "        \"GN_CNN_torch_model\", GNCNN\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fdd05",
   "metadata": {
    "id": "2cead394"
   },
   "source": [
    "## Define Training and Evaluation Environments\n",
    "\n",
    "**Training**: We will be training the PPO policy on episodes of length 32 time-steps. We will have 4 sub-processes (training environments) that will help to parallelize and speeden up episode rollouts. The *SimConfig* dataclass will define the parameters of the episode rollout: like length of episode rollout, whether to use log-replayed agents or simulated agents etc.\n",
    "\n",
    "**Evaluation**: We will evaluate the performance of the PPO policy on the *entire* scene (~248 time-steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c4a2f",
   "metadata": {
    "id": "0CAZm9UDo1C0"
   },
   "source": [
    "## Customize gym env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29286e2",
   "metadata": {
    "id": "IJC1ix47g1Y4"
   },
   "outputs": [],
   "source": [
    "class L5EnvWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, raster_size = 112, n_channels = 7):\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.n_channels = n_channels\n",
    "        self.raster_size = raster_size\n",
    "        obs_shape = (self.raster_size, self.raster_size, self.n_channels)\n",
    "        self.observation_space =gym.spaces.Box(low=0, high=1, shape=obs_shape, dtype=np.float32)\n",
    "\n",
    "    def step(self, action:  np.ndarray) -> GymStepOutput:\n",
    "        # return GymStepOutput(obs, reward[\"total\"], done, info)\n",
    "        output =  self.env.step(action)\n",
    "        onlyImageState = output.obs['image'].reshape(self.raster_size, self.raster_size, self.n_channels)\n",
    "        return GymStepOutput(onlyImageState, output.reward, output.done, output.info)\n",
    "\n",
    "    def reset(self) -> Dict[str, np.ndarray]:\n",
    "        return self.env.reset()['image'].reshape(self.raster_size, self.raster_size, self.n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a536b3f",
   "metadata": {
    "id": "XfXbbfjCg3aw"
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "train_eps_length = 32\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "# Register , how your env should be constructed (always with 5, or you can take values from the `config` EnvContext object):\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "\n",
    "tune.register_env(\"L5-CLE-V0\", lambda config: L5Env(**env_kwargs))\n",
    "tune.register_env(\"L5-CLE-V1\", lambda config: L5EnvWrapper(env = L5Env(**env_kwargs), \\\n",
    "                                                           raster_size= cfg['raster_params']['raster_size'][0], \\\n",
    "                                                           n_channels = 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa56982",
   "metadata": {
    "id": "rg8sxEnanVxL",
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62938d37",
   "metadata": {
    "id": "LlFBhHgZfx5f",
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.integrations.wandb import setup_wandb\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '/DATA/rllib_ppo_policy_training.ipynb'!wandb login 083592c84134c040dcca598c644c348d32540a08\n",
    "import wandb ## ref\n",
    "\n",
    "Resume stop tune: https://docs.ray.io/en/latest/tune/tutorials/tune-stopping.html\n",
    "\n",
    "tune.Tuner analysis: https://docs.ray.io/en/latest/rllib/rllib-training.html#basic-python-api\n",
    "\n",
    "get best result, load from dir: https://docs.ray.io/en/master/tune/examples/tune_analyze_results.html#trial-level-analysis-working-with-an-individual-result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d153be-1e42-4a57-8463-d50ce0dfcf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login 083592c84134c040dcca598c644c348d32540a08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f725e0e9-778f-4a31-a1e3-245f2d4f83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.integrations.wandb import setup_wandb\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '/DATA/rllib_sac_policy_training.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a62fa8-70dd-453d-b3da-ae2b045fde2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2cjepvw3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6dde1408e8434baa18f226a3caa622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.007 MB of 0.012 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.566350…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cool-totem-19</strong>: <a href=\"https://wandb.ai/pronton2001/l5kit2/runs/2cjepvw3\" target=\"_blank\">https://wandb.ai/pronton2001/l5kit2/runs/2cjepvw3</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230101_083038-2cjepvw3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2cjepvw3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd6ad8f74ff4dbeab6a3b09cc45739d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666868578334591, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/DATA/wandb/run-20230101_083620-3w3er9zh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/pronton2001/l5kit2/runs/3w3er9zh\" target=\"_blank\">lilac-resonance-20</a></strong> to <a href=\"https://wandb.ai/pronton2001/l5kit2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pronton2001/l5kit2/runs/3w3er9zh?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb98bd85a00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"l5kit2\", reinit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b7218",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gbfV227Jct2l",
    "outputId": "fd5c0af4-ad87-4a5d-a526-58dfad3b8646"
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/' + date\n",
    "\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'target_network_update_freq': 5,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'PrioritizedReplayBuffer',\n",
    "        'capacity': int(4e5),\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 1000,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    'store_buffer_in_checkpoints' : True,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 32,\n",
    "    'gamma': 0.8,\n",
    "}\n",
    "\n",
    "result_grid = tune.Tuner(\n",
    "    \"SAC\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 0, 'timesteps_total': int(6e6)},\n",
    "        local_dir=ray_result_logdir,\n",
    "        checkpoint_config=air.CheckpointConfig(num_to_keep=2, checkpoint_frequency = 10, checkpoint_score_attribute = 'episode_reward_mean')\n",
    "        ),\n",
    "    param_space=config_param_space).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164ab57-b068-4b75-ab94-24cdbff83d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 08:53:50,174\tINFO wandb.py:250 -- Already logged into W&B.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-01-01 09:44:56</td></tr>\n",
       "<tr><td>Running for: </td><td>00:51:06.62        </td></tr>\n",
       "<tr><td>Memory:      </td><td>231.2/503.2 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 64.0/64 CPUs, 1.0/1 GPUs, 0.0/468.12 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_L5-CLE-V1_cf7bb_00000</td><td>RUNNING </td><td>172.17.0.2:1654720</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2813.26</td><td style=\"text-align: right;\">80640</td><td style=\"text-align: right;\">-266.552</td><td style=\"text-align: right;\">            -58.2638</td><td style=\"text-align: right;\">            -395.789</td><td style=\"text-align: right;\">                31</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                           </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname    </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip   </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                           </th><th style=\"text-align: right;\">    pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                                   </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_L5-CLE-V1_cf7bb_00000</td><td style=\"text-align: right;\">                  80640</td><td>{&#x27;num_env_steps_sampled&#x27;: 80640, &#x27;num_env_steps_trained&#x27;: 2367488, &#x27;num_agent_steps_sampled&#x27;: 80640, &#x27;num_agent_steps_trained&#x27;: 2367488, &#x27;last_target_update_ts&#x27;: 80640, &#x27;num_target_updates&#x27;: 289}</td><td>{}              </td><td>2023-01-01_09-41-41</td><td>False </td><td style=\"text-align: right;\">                31</td><td>{}             </td><td style=\"text-align: right;\">            -58.2638</td><td style=\"text-align: right;\">             -266.552</td><td style=\"text-align: right;\">            -395.789</td><td style=\"text-align: right;\">                 252</td><td style=\"text-align: right;\">            2520</td><td>728aa68f10b24a71807ff882bf21f6b9</td><td>38d1f3f62321</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;custom_metrics&#x27;: {}, &#x27;learner_stats&#x27;: {&#x27;actor_loss&#x27;: 8.812812805175781, &#x27;critic_loss&#x27;: 0.39401447772979736, &#x27;alpha_loss&#x27;: -1.7508076429367065, &#x27;alpha_value&#x27;: 0.7067752, &#x27;log_alpha_value&#x27;: -0.34704265, &#x27;target_entropy&#x27;: -3.0, &#x27;policy_t&#x27;: 0.022778328508138657, &#x27;mean_q&#x27;: -8.996729850769043, &#x27;max_q&#x27;: 0.1875818520784378, &#x27;min_q&#x27;: -19.785879135131836}, &#x27;model&#x27;: {}, &#x27;num_grad_updates_lifetime&#x27;: 1156.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 1155.0, &#x27;td_error&#x27;: array([6.3309903, 3.6437593, 4.47351  , ..., 4.5698147, 3.6771932,\n",
       "       1.9372492], dtype=float32), &#x27;mean_td_error&#x27;: 3.2561662197113037}}, &#x27;num_env_steps_sampled&#x27;: 80640, &#x27;num_env_steps_trained&#x27;: 2367488, &#x27;num_agent_steps_sampled&#x27;: 80640, &#x27;num_agent_steps_trained&#x27;: 2367488, &#x27;last_target_update_ts&#x27;: 80640, &#x27;num_target_updates&#x27;: 289}       </td><td style=\"text-align: right;\">                        10</td><td>172.17.0.2</td><td style=\"text-align: right;\">                    80640</td><td style=\"text-align: right;\">                  2367488</td><td style=\"text-align: right;\">                  80640</td><td style=\"text-align: right;\">                             8064</td><td style=\"text-align: right;\">                2367488</td><td style=\"text-align: right;\">                           262144</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   63</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                       262144</td><td>{&#x27;cpu_util_percent&#x27;: 21.818246445497632, &#x27;ram_util_percent&#x27;: 45.19928909952607}</td><td style=\"text-align: right;\">1654720</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 543.2517422664438, &#x27;mean_inference_ms&#x27;: 38.52429465642051, &#x27;mean_action_processing_ms&#x27;: 2.763415269503187, &#x27;mean_env_wait_ms&#x27;: 403.98261404789645, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -58.263843804597855, &#x27;episode_reward_min&#x27;: -395.78902223706245, &#x27;episode_reward_mean&#x27;: -266.55183226853194, &#x27;episode_len_mean&#x27;: 31.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 252, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-239.0102435052395, -315.46955117583275, -350.2809314131737, -295.3525523394346, -375.7609887123108, -125.42248171940446, -213.39028072357178, -321.204388320446, -165.30160097777843, -278.51806247234344, -368.7421975284815, -222.80448591709137, -281.59126146137714, -100.46899828314781, -360.35176506638527, -324.17164608836174, -282.2768241763115, -358.5813331156969, -318.5083861798048, -273.05490189790726, -374.263945132494, -345.19716399908066, -329.61641654372215, -91.25386509299278, -317.0819436609745, -141.67730418592691, -313.07272773236036, -283.61031448841095, -384.7334594428539, -182.61282911151648, -315.39646857976913, -281.41736520826817, -269.46059215068817, -291.2918329387903, -149.78548197448254, -381.0407643914223, -278.61631241440773, -318.82015654444695, -393.1304204761982, -346.84480476379395, -206.43473315238953, -271.129971280694, -324.2219986617565, -122.4961024671793, -149.06780755519867, -318.75388012453914, -372.715628772974, -168.17121502757072, -394.420886695385, -297.1803601384163, -378.12008449435234, -263.08119531720877, -138.7313081510365, -130.89524812996387, -331.40234012156725, -341.44916197657585, -356.0900799408555, -258.9323396682739, -329.97140258550644, -213.98328721523285, -76.17018977552652, -199.0896539390087, -116.36399615556002, -256.76849437877536, -195.1551467180252, -278.98062989115715, -373.14412117004395, -162.08038310706615, -267.6527770459652, -395.78902223706245, -280.88155114650726, -212.79353946447372, -299.28727918863297, -276.9038734138012, -157.7410768866539, -239.55959382653236, -128.08969803154469, -157.7236249744892, -83.28353877365589, -375.7882164120674, -123.53195330128074, -315.46474266052246, -282.3662536740303, -307.5886910408735, -248.6706149019301, -379.85153594613075, -149.24158400297165, -341.6842777132988, -243.37295603752136, -136.38045568019152, -139.9097843170166, -252.9941124022007, -372.57703068852425, -172.69577984511852, -201.23314698413014, -362.9781885743141, -252.24430656433105, -339.5008824765682, -386.95836544036865, -180.5984003841877, -387.8370141983032, -338.3813439011574, -320.6602288633585, -182.11181201040745, -331.15034152567387, -295.0036338567734, -351.50891917943954, -370.22955053299665, -315.38987512886524, -219.2766069471836, -281.8167742192745, -337.45818120241165, -136.9562622308731, -326.5631651878357, -129.88796013593674, -372.9880223274231, -257.91548904776573, -346.78891310095787, -275.48679903149605, -276.64143876731396, -68.60699209570885, -262.44351311028004, -320.73733642697334, -317.57978264428675, -153.9463251233101, -360.0428886190057, -355.87650751695037, -318.85867639631033, -381.90275936294347, -173.61199155449867, -254.27757105231285, -294.07805059850216, -348.5094857811928, -332.40808129683137, -302.2544457241893, -224.95612782239914, -368.79041600227356, -308.72165640443563, -81.85456553474069, -373.8572616279125, -352.3852998614311, -291.7810097038746, -209.45745495706797, -298.30812910199165, -288.91846653819084, -355.6318387687206, -175.4664726704359, -160.70283073186874, -311.34211841225624, -130.31787486374378, -381.113315731287, -214.31183449178934, -177.55279672145844, -337.85355463624, -329.1560100913048, -248.05376362800598, -329.61016638576984, -347.2066205702722, -101.01703269779682, -365.98493924736977, -126.35004635620862, -310.025057464838, -291.4803636074066, -149.51297974959016, -324.3074985444546, -334.34783523902297, -324.5137799978256, -189.60005459189415, -278.78084920346737, -352.72923892736435, -378.7834988832474, -348.7612207531929, -259.84096771478653, -368.79233261942863, -192.33007282018661, -300.38981211185455, -154.30786885879934, -58.263843804597855, -93.19370300322771, -293.36644001305103, -304.796572946012, -168.984716668725, -318.72418519854546, -370.6341763138771, -307.6780381947756, -321.5807832479477, -337.34231155738235, -328.14320838451385, -77.33276599645615, -73.4064095467329, -179.20058937370777, -205.91496774554253, -329.2398442327976, -116.89023643359542, -379.51175037026405, -201.87782264314592, -385.4600729942322, -276.5918136537075, -352.695658326149, -304.96964110434055, -288.5717467814684, -310.58537343144417, -340.9859722480178, -310.1423180401325, -125.64173893630505, -323.93349212408066, -316.2093194723129, -140.2889180481434, -71.23376521468163, -185.49103969335556, -268.1483285985887, -333.3573638498783, -381.0383552014828, -366.2847504019737, -141.01020368933678, -326.9266217201948, -389.55089950561523, -129.7415716946125, -119.29032766819, -286.13683247566223, -311.6091835796833, -308.49939363077283, -138.90350463986397, -293.912226960063, -337.5189410299063, -315.37532091140747, -189.5664700344205, -363.56122364103794, -279.73857159912586, -65.6487163901329, -329.10058203339577, -358.5928415954113, -248.3689722418785, -341.20086854696274, -178.77139765024185, -291.5753686353564, -134.45915368944407, -78.27500683069229, -336.74289134144783, -326.5278294980526, -172.49989058077335, -251.43231546878815, -165.35790884494781, -86.14193984866142, -344.15941359102726, -299.9199951440096, -292.821906670928, -185.8763953447342, -318.7057000398636, -232.87917717546225, -344.14256888628006, -310.89024114608765], &#x27;episode_lengths&#x27;: [31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 543.2517422664438, &#x27;mean_inference_ms&#x27;: 38.52429465642051, &#x27;mean_action_processing_ms&#x27;: 2.763415269503187, &#x27;mean_env_wait_ms&#x27;: 403.98261404789645, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             2813.26</td><td style=\"text-align: right;\">            306.02</td><td style=\"text-align: right;\">       2813.26</td><td>{&#x27;training_iteration_time_ms&#x27;: 9504.646, &#x27;load_time_ms&#x27;: 133.039, &#x27;load_throughput&#x27;: 15393.991, &#x27;learn_time_ms&#x27;: 164.86, &#x27;learn_throughput&#x27;: 12422.695, &#x27;synch_weights_time_ms&#x27;: 598.243}</td><td style=\"text-align: right;\"> 1672566101</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">            80640</td><td style=\"text-align: right;\">                  10</td><td>cf7bb_00000</td><td style=\"text-align: right;\">       53.376</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/DATA/l5kit/ray_results/01-01-2023_15-53-49/SAC/SAC_L5-CLE-V1_cf7bb_00000_0_2023-01-01_08-53-50/checkpoint_000010)... Done. 0.3s\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "\n",
    "hcmTz = pytz.timezone(\"Asia/Ho_Chi_Minh\") \n",
    "date = datetime.datetime.now(hcmTz).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/' + date\n",
    "\n",
    "lr = 3e-3\n",
    "lr_start = 3e-4\n",
    "lr_end = 3e-5\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'target_network_update_freq': 1,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "        'capacity': int(1e5),\n",
    "        \"worker_side_prioritization\": True,\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 8000,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    " \n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    # 'store_buffer_in_checkpoints' : False,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    'train_batch_size': 2048,\n",
    "    'training_intensity' : 32, # (4x 'natural' value = 8)\n",
    "    'gamma': 0.8,\n",
    "    'twin_q' : True,\n",
    "    \"lr\": 3e-4,\n",
    "    \"min_sample_timesteps_per_iteration\": 8000,\n",
    "}\n",
    "\n",
    "result_grid = tune.Tuner(\n",
    "    \"SAC\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 0, 'timesteps_total': int(4e6)},\n",
    "        local_dir=ray_result_logdir,\n",
    "        checkpoint_config=air.CheckpointConfig(num_to_keep=2, checkpoint_frequency = 10, checkpoint_score_attribute = 'episode_reward_mean'),\n",
    "        callbacks=[WandbLoggerCallback(project=\"l5kit2\", \n",
    "\t\t\t\t\t\tsave_checkpoints=True),],\n",
    "        ),\n",
    "        \n",
    "    param_space=config_param_space).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "054bd96b-13ef-416c-8113-499ebce65ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-29 09:10:12</td></tr>\n",
       "<tr><td>Running for: </td><td>08:22:49.98        </td></tr>\n",
       "<tr><td>Memory:      </td><td>323.5/503.2 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/64 CPUs, 0/1 GPUs, 0.0/483.41 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_L5-CLE-V1_5af7a_00000</td><td>TERMINATED</td><td>172.17.0.2:2100464</td><td style=\"text-align: right;\">   249</td><td style=\"text-align: right;\">         30097.2</td><td style=\"text-align: right;\">2007936</td><td style=\"text-align: right;\"> -48.418</td><td style=\"text-align: right;\">            -4.97356</td><td style=\"text-align: right;\">            -342.104</td><td style=\"text-align: right;\">                31</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                                    </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname    </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip   </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                              </th><th style=\"text-align: right;\">    pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                  </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                                   </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_L5-CLE-V1_5af7a_00000</td><td style=\"text-align: right;\">                2007936</td><td>{&#x27;num_env_steps_sampled&#x27;: 2007936, &#x27;num_env_steps_trained&#x27;: 16254976, &#x27;num_agent_steps_sampled&#x27;: 2007936, &#x27;num_agent_steps_trained&#x27;: 16254976, &#x27;last_target_update_ts&#x27;: 2007936, &#x27;num_target_updates&#x27;: 7937}</td><td>{}              </td><td>2022-12-29_09-10-12</td><td>True  </td><td style=\"text-align: right;\">                31</td><td>{}             </td><td style=\"text-align: right;\">            -4.97356</td><td style=\"text-align: right;\">              -48.418</td><td style=\"text-align: right;\">            -342.104</td><td style=\"text-align: right;\">                 252</td><td style=\"text-align: right;\">           64764</td><td>6a1b193b49884b9783bc68502a9fba4d</td><td>38d1f3f62321</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;custom_metrics&#x27;: {}, &#x27;learner_stats&#x27;: {&#x27;actor_loss&#x27;: 10.66728687286377, &#x27;critic_loss&#x27;: 0.2743040919303894, &#x27;alpha_loss&#x27;: -8.968500137329102, &#x27;alpha_value&#x27;: 0.097858936, &#x27;log_alpha_value&#x27;: -2.3242283, &#x27;target_entropy&#x27;: -3.0, &#x27;policy_t&#x27;: 0.002813179511576891, &#x27;mean_q&#x27;: -10.056241989135742, &#x27;max_q&#x27;: -0.7284332513809204, &#x27;min_q&#x27;: -71.80377197265625}, &#x27;model&#x27;: {}, &#x27;num_grad_updates_lifetime&#x27;: 7937.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 7936.0, &#x27;td_error&#x27;: array([3.714016 , 0.5761843, 1.6428685, ..., 3.9594688, 2.1804185,\n",
       "       0.9676223], dtype=float32), &#x27;mean_td_error&#x27;: 2.5138769149780273}}, &#x27;num_env_steps_sampled&#x27;: 2007936, &#x27;num_env_steps_trained&#x27;: 16254976, &#x27;num_agent_steps_sampled&#x27;: 2007936, &#x27;num_agent_steps_trained&#x27;: 16254976, &#x27;last_target_update_ts&#x27;: 2007936, &#x27;num_target_updates&#x27;: 7937}       </td><td style=\"text-align: right;\">                       249</td><td>172.17.0.2</td><td style=\"text-align: right;\">                  2007936</td><td style=\"text-align: right;\">                 16254976</td><td style=\"text-align: right;\">                2007936</td><td style=\"text-align: right;\">                             8064</td><td style=\"text-align: right;\">               16254976</td><td style=\"text-align: right;\">                            65536</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   63</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                        65536</td><td>{&#x27;cpu_util_percent&#x27;: 38.95, &#x27;ram_util_percent&#x27;: 64.37439024390243}</td><td style=\"text-align: right;\">2100464</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 557.5587640255825, &#x27;mean_inference_ms&#x27;: 47.593003390485485, &#x27;mean_action_processing_ms&#x27;: 2.9690678893112814, &#x27;mean_env_wait_ms&#x27;: 426.11047655216566, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -4.973555717617273, &#x27;episode_reward_min&#x27;: -342.10410130023956, &#x27;episode_reward_mean&#x27;: -48.418040810326126, &#x27;episode_len_mean&#x27;: 31.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 252, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-7.4621262066066265, -41.47999408096075, -30.397633604705334, -49.24600240588188, -29.92940052598715, -72.64650725573301, -26.87973716855049, -11.681799755431712, -18.12396379560232, -19.913102217018604, -23.069430757313967, -11.442539423704147, -99.51352718472481, -22.244776694104075, -27.77426766604185, -98.61479258537292, -49.127030685544014, -22.231638342142105, -199.97455298900604, -76.25392800569534, -18.71334876306355, -42.81597018241882, -73.56289330124855, -7.541620695963502, -55.609064519405365, -41.371235713362694, -22.585967406630516, -12.339263431727886, -51.4718153513968, -80.66785857826471, -58.32361352443695, -87.72112779319286, -28.258968710899353, -12.798266559839249, -18.643772268667817, -42.05495078116655, -10.752920123748481, -7.985721813514829, -83.72157561779022, -9.54317206516862, -13.384278029203415, -68.8031562268734, -10.638589896261692, -119.62784695625305, -132.9736880660057, -96.00003948807716, -11.209963822737336, -10.219531135633588, -8.989193486981094, -8.054704411886632, -14.753779930993915, -11.431751469150186, -19.78944766148925, -63.47205105796456, -136.97895389050245, -12.408421391621232, -48.95064224302769, -101.75829920172691, -20.026732839643955, -6.55037109926343, -16.132280349731445, -25.484977897256613, -42.59231808036566, -33.8322284668684, -9.60510440915823, -8.720755230635405, -51.93710348010063, -10.440021116286516, -64.29593467526138, -64.36974440515041, -114.32647287100554, -66.07944963127375, -50.41681718826294, -40.00171493180096, -16.200324084609747, -29.237795993685722, -153.15099585056305, -168.20879462361336, -25.784470826387405, -78.44883043318987, -91.56494441628456, -166.42671021819115, -26.73681242763996, -80.4181410074234, -12.422316025942564, -101.45837111771107, -120.86603850126266, -51.918699741363525, -10.306001126766205, -10.808054637163877, -11.039475049823523, -10.298748157918453, -52.092963591217995, -10.005635634995997, -8.237097959034145, -103.76691523194313, -24.40737035870552, -13.600290849804878, -159.21457397937775, -81.14093877747655, -27.153657734394073, -24.96376897767186, -34.3931125625968, -22.96482305508107, -75.07949529588223, -15.354894362390041, -81.35158762335777, -60.97712790966034, -14.311687611043453, -33.83127050474286, -90.24751383066177, -8.340447791735642, -25.292251905426383, -9.46522231400013, -49.51268584281206, -65.61743873357773, -26.8861066326499, -7.616639997810125, -9.61411420069635, -17.074677165597677, -33.59195667505264, -127.78772127628326, -26.960867166519165, -11.141022946685553, -21.494155287742615, -8.329457223415375, -134.2124132886529, -207.68313336372375, -12.8949363976717, -53.89726731926203, -10.092645371332765, -60.15844654291868, -24.786295540630817, -135.5761418044567, -18.681159734725952, -41.64393958076835, -8.743692738935351, -61.73739293217659, -157.37170243263245, -36.76923814415932, -8.601557003334165, -133.0081479549408, -65.10541343688965, -7.6507846750319, -9.336956173181534, -58.92861983180046, -34.97503907978535, -14.337392661720514, -32.35617619752884, -83.36293375492096, -88.2966719083488, -11.025825656950474, -30.715365447103977, -342.10410130023956, -56.04067733883858, -82.09118078276515, -12.04058371623978, -16.880190078169107, -24.79690684378147, -56.83008548617363, -37.77252276428044, -51.7009187489748, -96.63202089071274, -8.88059919513762, -69.18232207000256, -10.123821537941694, -23.197871148586273, -61.34557843208313, -15.173034584149718, -10.205897832289338, -36.05493459291756, -25.538627788424492, -45.104613564908504, -8.038095336407423, -116.4073496311903, -23.685832545161247, -11.050906583666801, -11.857267241925001, -27.28685772791505, -30.16975475475192, -102.22034421097487, -56.96879315376282, -49.29720479995012, -10.223536057397723, -9.4553512185812, -7.503548703156412, -19.415623735636473, -54.286733977496624, -15.285702427849174, -86.9964390695095, -8.883664108812809, -84.89092037081718, -36.3870615363121, -7.033709031995386, -23.797568812966347, -123.78697862941772, -135.91445318609476, -47.04819901660085, -13.954086169600487, -13.610693532973528, -8.311992602422833, -9.553745400160551, -10.068777902051806, -60.71382158994675, -55.95641040802002, -82.21351046860218, -9.413188518024981, -39.387228824198246, -45.233738109469414, -24.85464497283101, -91.2011684179306, -127.55325359106064, -94.68607670068741, -154.2859691977501, -8.40143384411931, -21.433973629027605, -82.24952015280724, -112.48282658308744, -84.93823811411858, -75.58485485613346, -16.214268926531076, -34.300846844911575, -44.14082069694996, -27.32290068268776, -11.797557841986418, -62.649516731500626, -22.95103609189391, -99.95410460233688, -34.06992940232158, -81.63254825770855, -4.973555717617273, -49.15727382898331, -114.69648578763008, -18.213496141135693, -94.72749266214669, -43.1529616266489, -29.413159757852554, -16.90747994184494, -48.11836316809058, -15.246637467294931, -9.59222056902945, -44.99032598733902, -55.53623207658529, -12.991382762789726, -206.02356186509132, -55.89227467775345, -11.870953384786844, -52.908058792352676, -60.95068273693323, -33.86251822859049, -10.461833715438843, -53.137717263773084], &#x27;episode_lengths&#x27;: [31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 557.5587640255825, &#x27;mean_inference_ms&#x27;: 47.593003390485485, &#x27;mean_action_processing_ms&#x27;: 2.9690678893112814, &#x27;mean_env_wait_ms&#x27;: 426.11047655216566, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             30097.2</td><td style=\"text-align: right;\">            119.19</td><td style=\"text-align: right;\">       30097.2</td><td>{&#x27;training_iteration_time_ms&#x27;: 3943.931, &#x27;load_time_ms&#x27;: 185.149, &#x27;load_throughput&#x27;: 11061.376, &#x27;learn_time_ms&#x27;: 210.285, &#x27;learn_throughput&#x27;: 9739.143, &#x27;synch_weights_time_ms&#x27;: 458.456}</td><td style=\"text-align: right;\"> 1672305012</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          2007936</td><td style=\"text-align: right;\">                 249</td><td>5af7a_00000</td><td style=\"text-align: right;\">      56.4943</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 09:10:12,594\tINFO tune.py:762 -- Total run time: 30170.23 seconds (30169.98 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "\n",
    "hcmTz = pytz.timezone(\"Asia/Ho_Chi_Minh\") \n",
    "date = datetime.datetime.now(hcmTz).strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/' + date\n",
    "\n",
    "lr = 3e-3\n",
    "lr_start = 3e-4\n",
    "lr_end = 3e-5\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'target_network_update_freq': 1,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "        'capacity': int(1e5),\n",
    "        \"worker_side_prioritization\": True,\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 8000,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    " \n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    # 'store_buffer_in_checkpoints' : False,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    'train_batch_size': 2048,\n",
    "    # 'training_intensity' : 1000,\n",
    "    'gamma': 0.8,\n",
    "    'twin_q' : True,\n",
    "    \"lr\": 3e-4,\n",
    "    \"min_sample_timesteps_per_iteration\": 8000,\n",
    "}\n",
    "\n",
    "result_grid = tune.Tuner(\n",
    "    \"SAC\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 0, 'timesteps_total': int(2e6)},\n",
    "        local_dir=ray_result_logdir,\n",
    "        checkpoint_config=air.CheckpointConfig(num_to_keep=2, checkpoint_frequency = 10, checkpoint_score_attribute = 'episode_reward_mean')\n",
    "        ),\n",
    "    param_space=config_param_space).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8bf4329-c187-46e8-8658-bb867e5fc90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'target_network_update_freq': 1,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "        'capacity': int(1e5),\n",
    "        \"worker_side_prioritization\": True,\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 8000,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    " \n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    # 'store_buffer_in_checkpoints' : False,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    'train_batch_size': 2048,\n",
    "    # 'training_intensity' : 1000,\n",
    "    'gamma': 0.8,\n",
    "    'twin_q' : True,\n",
    "    \"lr\": 3e-4,\n",
    "    \"min_sample_timesteps_per_iteration\": 8000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87b2897c-ecd0-4402-be62-655d7f194e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-29 15:00:53</td></tr>\n",
       "<tr><td>Running for: </td><td>00:04:32.61        </td></tr>\n",
       "<tr><td>Memory:      </td><td>270.1/503.2 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 64.0/64 CPUs, 1.0/1 GPUs, 0.0/483.41 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_L5-CLE-V1_f4f69_00000</td><td>RUNNING </td><td>172.17.0.2:137387</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">           30255</td><td style=\"text-align: right;\">2016000</td><td style=\"text-align: right;\">-137.817</td><td style=\"text-align: right;\">             -15.617</td><td style=\"text-align: right;\">            -371.548</td><td style=\"text-align: right;\">                31</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                                    </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname    </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip   </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                          </th><th style=\"text-align: right;\">   pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                               </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                                  </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_L5-CLE-V1_f4f69_00000</td><td style=\"text-align: right;\">                2016000</td><td>{&#x27;num_env_steps_sampled&#x27;: 2016000, &#x27;num_env_steps_trained&#x27;: 16320512, &#x27;num_agent_steps_sampled&#x27;: 2016000, &#x27;num_agent_steps_trained&#x27;: 16320512, &#x27;last_target_update_ts&#x27;: 2016000, &#x27;num_target_updates&#x27;: 7969}</td><td>{}              </td><td>2022-12-29_14-59-58</td><td>False </td><td style=\"text-align: right;\">                31</td><td>{}             </td><td style=\"text-align: right;\">             -15.617</td><td style=\"text-align: right;\">             -137.817</td><td style=\"text-align: right;\">            -371.548</td><td style=\"text-align: right;\">                 252</td><td style=\"text-align: right;\">           65016</td><td>6a1b193b49884b9783bc68502a9fba4d</td><td>38d1f3f62321</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;custom_metrics&#x27;: {}, &#x27;learner_stats&#x27;: {&#x27;actor_loss&#x27;: 4.579573631286621, &#x27;critic_loss&#x27;: 0.9118623733520508, &#x27;alpha_loss&#x27;: -9.704286575317383, &#x27;alpha_value&#x27;: 0.09693226, &#x27;log_alpha_value&#x27;: -2.3337429, &#x27;target_entropy&#x27;: -3.0, &#x27;policy_t&#x27;: -0.08073669672012329, &#x27;mean_q&#x27;: -3.388627767562866, &#x27;max_q&#x27;: -0.7259072065353394, &#x27;min_q&#x27;: -15.54305648803711}, &#x27;model&#x27;: {}, &#x27;num_grad_updates_lifetime&#x27;: 32.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 31.0, &#x27;td_error&#x27;: array([1.2998202, 8.56468  , 1.5235349, ..., 2.8340416, 3.6547613,\n",
       "       1.2337224], dtype=float32), &#x27;mean_td_error&#x27;: 4.344608306884766}}, &#x27;num_env_steps_sampled&#x27;: 2016000, &#x27;num_env_steps_trained&#x27;: 16320512, &#x27;num_agent_steps_sampled&#x27;: 2016000, &#x27;num_agent_steps_trained&#x27;: 16320512, &#x27;last_target_update_ts&#x27;: 2016000, &#x27;num_target_updates&#x27;: 7969}       </td><td style=\"text-align: right;\">                         1</td><td>172.17.0.2</td><td style=\"text-align: right;\">                  2016000</td><td style=\"text-align: right;\">                 16320512</td><td style=\"text-align: right;\">                2016000</td><td style=\"text-align: right;\">                             8064</td><td style=\"text-align: right;\">               16320512</td><td style=\"text-align: right;\">                            65536</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   63</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                        65536</td><td>{&#x27;cpu_util_percent&#x27;: 60.70904977375565, &#x27;ram_util_percent&#x27;: 42.32488687782805}</td><td style=\"text-align: right;\">137387</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 691.7444644724308, &#x27;mean_inference_ms&#x27;: 41.91511855095612, &#x27;mean_action_processing_ms&#x27;: 3.431972257789366, &#x27;mean_env_wait_ms&#x27;: 584.0683852668678, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -15.617014065384865, &#x27;episode_reward_min&#x27;: -371.54844295978546, &#x27;episode_reward_mean&#x27;: -137.81730142700079, &#x27;episode_len_mean&#x27;: 31.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 252, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-299.97706861048937, -51.82022622227669, -212.13150823116302, -244.13909198343754, -197.46283899247646, -31.607199588790536, -96.4726347476244, -15.617014065384865, -273.5172915905714, -194.24902094714344, -129.61998998373747, -65.69232455454767, -19.393883276730776, -111.7408323250711, -59.09626119583845, -90.9191816598177, -199.88144850730896, -299.2814950942993, -190.75740267336369, -130.1176925431937, -179.24520199000835, -194.28794536739588, -143.29140626639128, -101.1886000931263, -86.3916173428297, -29.176321119070053, -35.31472562253475, -223.68560089170933, -74.8477296680212, -54.759615938179195, -307.39633852243423, -240.48044553399086, -268.46005898714066, -223.39069479703903, -220.1556041240692, -50.030099771916866, -80.1811374425888, -28.63940942659974, -222.0825450643897, -63.31155708618462, -110.8121508359909, -40.13294491916895, -269.29217824339867, -186.04005989432335, -249.58123522996902, -218.90602142363787, -47.48398283869028, -55.637234918773174, -52.47745594102889, -111.15736995637417, -211.80621452629566, -43.390553280711174, -177.45844892412424, -52.30602751299739, -214.2268007695675, -161.82819437980652, -192.73150944709778, -48.21109406277537, -227.2928847670555, -103.89885324984789, -30.138481315225363, -111.42090831696987, -158.19647543132305, -182.80938386917114, -251.64277704060078, -137.9156246036291, -140.02911753207445, -98.01596263051033, -134.044519148767, -111.15653241798282, -71.10387574322522, -225.6438679099083, -212.01682150363922, -121.28016351722181, -75.78648805245757, -153.77385725080967, -53.40755498409271, -168.57436906546354, -39.32255797833204, -70.8449877682142, -32.380650751292706, -246.21190083026886, -43.56784425675869, -24.78948475793004, -133.95375065878034, -185.20826063677669, -75.8833856601268, -247.84678468108177, -165.07357239723206, -332.57243210077286, -172.52162861824036, -167.6060889363289, -46.20060350000858, -270.73676973581314, -101.12249380350113, -50.965405613183975, -371.54844295978546, -25.443911347538233, -161.73639491945505, -43.21673648804426, -34.5110229998827, -198.44270712137222, -76.74124410748482, -88.40089039504528, -337.2680090069771, -147.06688775122166, -67.2424168586731, -49.01937335729599, -171.42071080207825, -146.56798292323947, -173.93097941577435, -31.48320733755827, -94.1955065280199, -23.609794601798058, -96.3097610771656, -236.95774947106838, -97.59911411628127, -72.61437848210335, -180.87512730807066, -129.8502264805138, -143.43173751235008, -93.29107657074928, -128.40934970974922, -271.45442797709256, -192.11385215818882, -163.12449376285076, -314.89704218506813, -289.9468065202236, -116.46002896130085, -150.59363002888858, -130.35035149008036, -256.71769541502, -93.11557127535343, -250.47537092864513, -164.41879165172577, -71.24733397364616, -139.42685773968697, -202.00427490472794, -104.31808914244175, -210.9410725682974, -194.30858905240893, -89.75386482477188, -67.03705172333866, -160.9048422574997, -215.08678121119738, -264.1829191148281, -152.43290308117867, -72.9229040145874, -276.17744693160057, -196.89465822279453, -96.54025993961841, -68.37835693359375, -21.348181121982634, -31.92421041801572, -123.40187205374241, -90.50316984020174, -160.30389396846294, -167.4033802896738, -71.28940810263157, -32.464180406183004, -252.95062878355384, -196.7002201974392, -210.17943699657917, -56.82348436117172, -138.51692804694176, -91.46426229923964, -254.60068672895432, -143.89270337671041, -71.78226737631485, -46.60442142933607, -46.624403320252895, -70.64460425078869, -120.41957493126392, -86.16039713518694, -142.7494396492839, -267.28318813443184, -82.15140162222087, -156.07647028565407, -186.9594401270151, -63.831169694662094, -150.02693651244044, -191.60844258964062, -84.98108759522438, -203.62129264511168, -43.943675100803375, -55.66991034895182, -126.72345610335469, -283.9452374931425, -80.56798090040684, -133.2169153690338, -55.0657594576478, -88.30508452653885, -53.43094354867935, -64.081110522151, -207.8457684367895, -56.04468463920057, -230.81134974956512, -59.9131864765659, -72.7744899392128, -237.27829033136368, -121.15408451855183, -126.59941921383142, -78.40274704247713, -56.59736351296306, -137.6304468885064, -57.37811692850664, -208.78320770338178, -56.395890951156616, -191.32112161070108, -262.88904443383217, -30.63711839914322, -58.60731145367026, -42.97315649688244, -43.484818050055765, -103.17349380254745, -39.4192226678133, -65.10727168619633, -301.94181221723557, -207.65956818684936, -272.50115633010864, -64.54533440619707, -160.38112823665142, -274.56690204143524, -107.91420528292656, -279.497002184391, -186.86970533430576, -66.16285207122564, -155.11157170310616, -109.60744011029601, -177.88816595077515, -144.8501342087984, -183.32364154607058, -35.32881237566471, -98.80114330351353, -132.91177412495017, -226.34882310405374, -144.25793534331024, -156.4375006519258, -92.1831620708108, -125.86796532571316, -126.13164404407144, -148.4325664229691, -79.81684523820877, -168.8368287011981, -218.18234498798847, -117.6562134847045, -296.0146112330258, -47.064086839556694, -172.08175939507782, -191.52176237478852, -53.177558897063136, -104.96447165310383], &#x27;episode_lengths&#x27;: [31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 691.7444644724308, &#x27;mean_inference_ms&#x27;: 41.91511855095612, &#x27;mean_action_processing_ms&#x27;: 3.431972257789366, &#x27;mean_env_wait_ms&#x27;: 584.0683852668678, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             157.784</td><td style=\"text-align: right;\">           157.784</td><td style=\"text-align: right;\">         30255</td><td>{&#x27;training_iteration_time_ms&#x27;: 7780.57, &#x27;load_time_ms&#x27;: 205.295, &#x27;load_throughput&#x27;: 9975.888, &#x27;learn_time_ms&#x27;: 239.504, &#x27;learn_throughput&#x27;: 8551.009, &#x27;synch_weights_time_ms&#x27;: 2729.168}</td><td style=\"text-align: right;\"> 1672325998</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          2016000</td><td style=\"text-align: right;\">                 250</td><td>f4f69_00000</td><td style=\"text-align: right;\">      54.8865</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 15:00:51,943\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2022-12-29 15:00:54,331\tERROR tune.py:758 -- Trials did not complete: [SAC_L5-CLE-V1_f4f69_00000]\n",
      "2022-12-29 15:00:54,333\tINFO tune.py:762 -- Total run time: 272.99 seconds (272.61 seconds for the tuning loop).\n",
      "2022-12-29 15:00:54,333\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f0903752fd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1672326111 on cpu 28 ***\n",
      "PC: @     0x7f0aa3d5b46e  (unknown)  epoll_wait\n",
      "    @     0x7f0aa3c7f090  (unknown)  (unknown)\n",
      "[2022-12-29 15:01:51,032 E 1533378 1533378] logging.cc:361: *** SIGTERM received at time=1672326111 on cpu 28 ***\n",
      "[2022-12-29 15:01:51,032 E 1533378 1533378] logging.cc:361: PC: @     0x7f0aa3d5b46e  (unknown)  epoll_wait\n",
      "[2022-12-29 15:01:51,032 E 1533378 1533378] logging.cc:361:     @     0x7f0aa3c7f090  (unknown)  (unknown)\n"
     ]
    }
   ],
   "source": [
    "# config_param_space['stop']['timesteps_total'] = 3e-5\n",
    "path_to_trained_agent_checkpoint = 'l5kit/ray_results/29-12-2022_07-47-22/SAC/SAC_L5-CLE-V1_5af7a_00000_0_2022-12-29_00-47-23/checkpoint_000249'\n",
    "from ray.rllib.algorithms.sac import SAC\n",
    "ray.tune.run(SAC, config=config_param_space, restore=path_to_trained_agent_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae5452-4d9c-47a7-bc98-1056a9d927c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/' + date\n",
    "lr = 3e-3\n",
    "lr_start = 3e-4\n",
    "lr_end = 3e-5\n",
    "\n",
    "config_param_space = {\n",
    "    \"env\": \"L5-CLE-V1\",\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 63,\n",
    "    \"num_envs_per_worker\": train_envs,\n",
    "    'q_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'policy_model_config' : {\n",
    "            # \"dim\": 112,\n",
    "            # \"conv_filters\" : [[64, [7,7], 3], [32, [11,11], 3], [32, [11,11], 3]],\n",
    "            # \"conv_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [256],\n",
    "            \"post_fcnet_activation\": \"relu\",\n",
    "        },\n",
    "    'tau': 0.005,\n",
    "    'n_step': 1\n",
    "    'target_network_update_freq': 5,\n",
    "    'replay_buffer_config':{\n",
    "        'type': 'MultiAgentPrioritizedReplayBuffer',\n",
    "        'capacity': int(3e5),\n",
    "    },\n",
    "    'num_steps_sampled_before_learning_starts': 256,\n",
    "    \n",
    "    'target_entropy': 'auto',\n",
    "#     \"model\": {\n",
    "#         \"custom_model\": \"GN_CNN_torch_model\",\n",
    "#         \"custom_model_config\": {'feature_dim':128},\n",
    "#     },\n",
    "    '_disable_preprocessor_api': True,\n",
    "     \"eager_tracing\": True,\n",
    "     \"restart_failed_sub_environments\": True,\n",
    "    # 'train_batch_size': 4000,\n",
    "    # 'sgd_minibatch_size': 256,\n",
    "    # 'num_sgd_iter': 16,\n",
    "    'seed': 42,\n",
    "    'batch_mode': 'truncate_episodes',\n",
    "    \"rollout_fragment_length\": 32,\n",
    "    'gamma': 0.8,\n",
    "    \"lr_schedule\": [\n",
    "        [1e6, lr_start],\n",
    "        [2e6, lr_end],\n",
    "    ],\n",
    "    \"lr\": lr,\n",
    "}\n",
    "\n",
    "result_grid = tune.Tuner(\n",
    "    \"SAC\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 0, 'timesteps_total': int(3e6)},\n",
    "        local_dir=ray_result_logdir,\n",
    "        checkpoint_config=air.CheckpointConfig(num_to_keep=2, checkpoint_frequency = 10, checkpoint_score_attribute = 'episode_reward_mean')\n",
    "        ),\n",
    "    param_space=config_param_space).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f28fe783",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RTK45EUeonWl",
    "outputId": "1a0ff185-7c8c-4cfb-8d1c-4dcb71cd7fb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 14:46:39,383\tINFO experiment_analysis.py:795 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "2022-12-29 14:46:39,426\tINFO trial_runner.py:688 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
      "2022-12-29 14:46:39,427\tINFO trial_runner.py:825 -- Using following checkpoint to resume: /DATA/l5kit/ray_results/29-12-2022_07-47-22/SAC/experiment_state-2022-12-29_00-47-22.json\n",
      "2022-12-29 14:46:39,429\tWARNING trial_runner.py:830 -- Attempting to resume experiment from /DATA/l5kit/ray_results/29-12-2022_07-47-22/SAC. This will ignore any new changes to the specification.\n",
      "2022-12-29 14:46:39,436\tINFO tune.py:653 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-29 14:46:39</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.02        </td></tr>\n",
       "<tr><td>Memory:      </td><td>144.4/503.2 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/64 CPUs, 0/1 GPUs, 0.0/483.41 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_L5-CLE-V1_5af7a_00000</td><td>TERMINATED</td><td>172.17.0.2:2100464</td><td style=\"text-align: right;\">   249</td><td style=\"text-align: right;\">         30097.2</td><td style=\"text-align: right;\">2007936</td><td style=\"text-align: right;\"> -48.418</td><td style=\"text-align: right;\">            -4.97356</td><td style=\"text-align: right;\">            -342.104</td><td style=\"text-align: right;\">                31</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 14:46:39,596\tINFO tune.py:762 -- Total run time: 0.17 seconds (0.00 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "train_envs = 4\n",
    "ray_result_logdir = '/DATA/l5kit/ray_results/29-12-2022_07-47-22'\n",
    "\n",
    "tuner = tune.Tuner.restore(\n",
    "    path=ray_result_logdir + '/SAC'\n",
    ")\n",
    "result = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f20c94-38cb-44a7-96ce-48ba11b430fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = result.get_best_result(metric=\"episode_reward_mean\", mode = 'max')\n",
    "best_checkpoint = best_result.checkpoint\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb196340-7ec2-471a-9857-1cd540a96a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 1\n"
     ]
    }
   ],
   "source": [
    "num_results = len(result)\n",
    "print(\"Number of results:\", num_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce9e89-8641-4897-97f8-7b90baf82edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_best_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3625c4c7-cc99-47ae-9a19-f70d10ca91fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77798ffb-abfd-4021-888d-a66d51a03481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ray.air.result.Result"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1671780714 on cpu 2 ***\n",
      "PC: @     0x7f4dbec0d46e  (unknown)  epoll_wait\n",
      "    @     0x7f4dbeb31090  (unknown)  (unknown)\n",
      "[2022-12-23 07:31:54,799 E 2700257 2700257] logging.cc:361: *** SIGTERM received at time=1671780714 on cpu 2 ***\n",
      "[2022-12-23 07:31:54,799 E 2700257 2700257] logging.cc:361: PC: @     0x7f4dbec0d46e  (unknown)  epoll_wait\n",
      "[2022-12-23 07:31:54,799 E 2700257 2700257] logging.cc:361:     @     0x7f4dbeb31090  (unknown)  (unknown)\n"
     ]
    }
   ],
   "source": [
    "type(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5da07f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mbest_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      2\u001b[0m result_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_reward_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "result_df = best_result.metrics_dataframe() \n",
    "result_df[['episode_reward_mean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8618e3",
   "metadata": {
    "id": "4fipqZymhM1l"
   },
   "source": [
    "NOTE: Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
    "\n",
    "2022-12-04 05:50:38,570\tINFO experiment_analysis.py:795 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
    "\n",
    "2022-12-04 05:50:39,684\tINFO trial_runner.py:601 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
    "2022-12-04 05:50:39,687\tINFO trial_runner.py:738 -- Using following checkpoint to resume: /content/drive/MyDrive/Colab Notebooks/l5kit/ray_results/PPO/experiment_state-2022-12-04_05-28-55.json\n",
    "\n",
    "2022-12-04 05:50:39,710\tWARNING trial_runner.py:743 -- Attempting to resume experiment from /content/drive/MyDrive/Colab Notebooks/l5kit/ray_results/PPO. This will ignore any new changes to the specification.\n",
    "\n",
    "2022-12-04 05:50:40,703\tINFO tune.py:668 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fed29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4p68J7JqSddH",
    "outputId": "c10e3423-caa6-48b5-caea-31fe9893fde5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 04:42:57,593\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-12-04 04:42:57,599\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2022-12-04 04:43:38,550\tWARNING catalog.py:641 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!\n",
      "2022-12-04 04:43:51,371\tINFO trainable.py:164 -- Trainable.setup took 53.780 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-12-04 04:43:51,397\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "train_envs=2\n",
    "ray_result_logdir = '/content/drive/MyDrive/Colab Notebooks/l5kit/ray_results'\n",
    "# Create the Trainer.\n",
    "algo = ppo.PPO(\n",
    "        env=\"L5-CLE-V1\",\n",
    "        config={\n",
    "            \"framework\": \"torch\",\n",
    "            \"num_gpus\": 1,\n",
    "            \"num_workers\": 2,\n",
    "            \"num_envs_per_worker\": train_envs,\n",
    "            'num_sgd_iter': 5,\n",
    "            'sgd_minibatch_size': 256,\n",
    "            'num_cpus_per_worker': 0,  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "            \"model\": {\n",
    "                \"custom_model\": \"GN_CNN_torch_model\",\n",
    "                \"custom_model_config\": {'feature_dim':128},\n",
    "            },\n",
    "            '_disable_preprocessor_api': True,\n",
    "        },\n",
    "        logger_creator=custom_log_creator(os.path.expanduser(ray_result_logdir), 'L5_PPO')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b16aee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "OyKfMUNfpTfq",
    "outputId": "a6ff9bc8-f0b8-4e3b-c2aa-80d251494529"
   },
   "outputs": [],
   "source": [
    "checkpoint_path =  '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/'+ str(datetime.date.today())\n",
    "for i in range(1, 1000):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = algo.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 10 == 0:\n",
    "       checkpoint = algo.save(checkpoint_dir= checkpoint_path)\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff44cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvbCuZHCwh44",
    "outputId": "d9246d10-3c7f-4fc1-f17b-645061412323"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 01:13:59,915\tWARNING worker.py:1839 -- WARNING: 8 PYTHON worker processes have been started on node: 777dc243b4add8ac085f8950774bd32fe348c2829250d7da57d1a177 with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
      "2022-12-04 01:14:25,297\tWARNING catalog.py:641 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!\n",
      "2022-12-04 01:14:25,596\tINFO trainable.py:164 -- Trainable.setup took 25.769 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-12-04 01:14:25,601\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "2022-12-04 01:14:26,933\tINFO trainable.py:766 -- Restored on 172.28.0.12 from checkpoint: /content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/2022-12-02/checkpoint_000130\n",
      "2022-12-04 01:14:26,936\tINFO trainable.py:775 -- Current state after restoring: {'_iteration': 130, '_timesteps_total': None, '_time_total': 14015.14718747139, '_episodes_total': 16772}\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/2022-12-02/checkpoint_000130'\n",
    "config={\n",
    "            \"framework\": \"torch\",\n",
    "            \"num_gpus\": 1,\n",
    "            \"num_workers\": 2,\n",
    "            \"num_envs_per_worker\": train_envs,\n",
    "            'num_sgd_iter': 15,\n",
    "            'sgd_minibatch_size': 128,\n",
    "            'num_cpus_per_worker': 0,  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "            \"model\": {\n",
    "                \"custom_model\": \"GN_CNN_torch_model\",\n",
    "                \"custom_model_config\": {'feature_dim':128},\n",
    "            },\n",
    "            '_disable_preprocessor_api': True,\n",
    "        }\n",
    "algo = ppo.PPO(config=config, env='L5-CLE-V1')\n",
    "algo.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13a811",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eR892sUGybQR",
    "outputId": "4a39bb59-2025-4cca-b3ee-a031312eb0c3"
   },
   "outputs": [],
   "source": [
    "checkpoint_path =  '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/'+ str(datetime.date.today())\n",
    "for i in range(1, 1000):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = algo.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 10 == 0:\n",
    "       checkpoint = algo.save(checkpoint_dir= checkpoint_path)\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9cefd1",
   "metadata": {
    "id": "GnXlEIp3xktb"
   },
   "outputs": [],
   "source": [
    "checkpoint_path =  '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/'+ str(datetime.date.today())\n",
    "for i in range(1, 1000):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = algo.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 1 == 0:\n",
    "       checkpoint = algo.save(checkpoint_dir= checkpoint_path)\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea4f53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvrD01hihER4",
    "outputId": "40bfcbc9-a62c-49ba-f914-a3dbe934a2ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 14:57:14,922\tWARNING deprecation.py:47 -- DeprecationWarning: `algo = Algorithm(env='L5-CLE-V1', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('L5-CLE-V1').build()` instead. This will raise an error in the future!\n",
      "2022-12-14 14:57:14,925\tINFO algorithm_config.py:2503 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2022-12-14 14:57:14,964\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2022-12-14 14:58:13,797\tINFO trainable.py:172 -- Trainable.setup took 58.834 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-12-14 14:58:13,800\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "train_envs = 2\n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 1\n",
    "# config[\"framework\"] = 'tf2'\n",
    "config[\"num_workers\"] = 2\n",
    "config[\"num_envs_per_worker\"] = train_envs\n",
    "config['_disable_preprocessor_api'] = True,\n",
    "config[\"model\"][\"dim\"] = 112\n",
    "config[\"model\"][\"conv_filters\"] = [[64, 7, 3], [32, 11, 3], [32, 11, 3]]\n",
    "config['num_sgd_iter'] = 1\n",
    "config['sgd_minibatch_size'] = 256\n",
    "# config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "# config['env_config'] = env_kwargs \n",
    "# config[\"log_level\"] = 1\n",
    "# config[\"evaluation_interval\"] = 1 # change to 10000\n",
    "# config[\"evaluation_duration\"] = \"auto\"\n",
    "# config[\"evaluation_parallel_to_training\"] = True,\n",
    "# config[\"evaluation_duration_unit\"] = \"timesteps\"\n",
    "# config[\"evaluation_num_workers\"] = 3\n",
    "# config[\"enable_async_evaluation\"] = True,\n",
    "\n",
    "config[\"model\"][\"conv_activation\"] = 'relu'\n",
    "config[\"model\"][\"post_fcnet_hiddens\"] =  [256]\n",
    "config[\"model\"][\"post_fcnet_activation\"] = 'relu'\n",
    "# config[\"train_batch_size\"] = 200\n",
    "algo = ppo.PPO(config=config, env=\"L5-CLE-V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234eeb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ErrnMkgMFowP",
    "outputId": "70c40c5a-1b39-4324-fcfc-6bcc57464ec0"
   },
   "outputs": [],
   "source": [
    "checkpoint_path =  '/content/drive/MyDrive/Colab Notebooks/l5kit/rllib_logs/'+ str(datetime.date.today())\n",
    "for i in range(1, 1000):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = algo.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 10 == 0:\n",
    "       checkpoint = algo.save(checkpoint_dir= checkpoint_path)\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b6fd8",
   "metadata": {
    "id": "pIkWVnTRFnYM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9c2d8ba",
   "metadata": {
    "id": "E90LSvLYyHrL"
   },
   "source": [
    "## Stable baselines 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d58907",
   "metadata": {
    "id": "b04c8313"
   },
   "outputs": [],
   "source": [
    "# Train on episodes of length 32 time steps\n",
    "train_eps_length = 32\n",
    "train_envs = 4\n",
    "\n",
    "# Evaluate on entire scene (~248 time steps)\n",
    "eval_eps_length = None\n",
    "eval_envs = 1\n",
    "\n",
    "# make train env\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "env = make_vec_env(\"L5-CLE-v0\", env_kwargs=env_kwargs, n_envs=train_envs,\n",
    "                   vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"fork\"})\n",
    "\n",
    "# make eval env\n",
    "validation_sim_cfg = SimulationConfigGym()\n",
    "validation_sim_cfg.num_simulation_steps = None\n",
    "eval_env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, \\\n",
    "                   'return_info': True, 'train': False, 'sim_cfg': validation_sim_cfg}\n",
    "eval_env = make_vec_env(\"L5-CLE-v0\", env_kwargs=eval_env_kwargs, n_envs=eval_envs,\n",
    "                        vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"fork\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eafb8bd",
   "metadata": {
    "id": "9dfc8b1a"
   },
   "source": [
    "### Define backbone feature extractor\n",
    "\n",
    "The backbone feature extractor is shared between the policy and the value networks. The feature extractor *simple_gn* is composed of two convolutional networks followed by a fully connected layer, with ReLU activation. The feature extractor output is passed to both the policy and value networks composed of two fully connected layers with tanh activation (SB3 default).\n",
    "\n",
    "We perform **group normalization** after every convolutional layer. Empirically, we found that group normalization performs far superior to batch normalization. This can be attributed to the fact that activation statistics change quickly in on-policy algorithms (PPO is on-policy) while batch-norm learnable parameters can be slow to update causing training issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf5d68",
   "metadata": {
    "id": "4da5ac39"
   },
   "outputs": [],
   "source": [
    "# A simple 2 Layer CNN architecture with group normalization\n",
    "model_arch = 'simple_gn'\n",
    "features_dim = 128\n",
    "\n",
    "# Custom Feature Extractor backbone\n",
    "policy_kwargs = {\n",
    "    \"features_extractor_class\": CustomFeatureExtractor,\n",
    "    \"features_extractor_kwargs\": {\"features_dim\": features_dim, \"model_arch\": model_arch},\n",
    "    \"normalize_images\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65163ffc",
   "metadata": {
    "id": "24ec4f23"
   },
   "source": [
    "### Clipping Schedule\n",
    "\n",
    "We linearly decrease the value of the clipping parameter $\\epsilon$ as the PPO training progress as it shows improved training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb86198",
   "metadata": {
    "id": "dc28b605"
   },
   "outputs": [],
   "source": [
    "# Clipping schedule of PPO epsilon parameter\n",
    "start_val = 0.1\n",
    "end_val = 0.01\n",
    "training_progress_ratio = 1.0\n",
    "clip_schedule = get_linear_fn(start_val, end_val, training_progress_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75663963",
   "metadata": {
    "id": "8596deb6"
   },
   "source": [
    "### Hyperparameters for PPO. \n",
    "\n",
    "For detailed description, refer https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/ppo/ppo.html#PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304879a9",
   "metadata": {
    "id": "998a927f"
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "num_rollout_steps = 256\n",
    "gamma = 0.8\n",
    "gae_lambda = 0.9\n",
    "n_epochs = 10\n",
    "seed = 42\n",
    "batch_size = 64\n",
    "tensorboard_log = '/content/drive/MyDrive/Colab Notebooks/l5kit/tb_logs/' + str(datetime.date.today()) + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9a469",
   "metadata": {
    "id": "a310190e"
   },
   "source": [
    "### Define the PPO Policy.\n",
    "\n",
    "SB3 provides an easy interface to the define the PPO policy. Note: We do need to tweak appropriate hyperparameters and the custom policy backbone has been defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713be52e",
   "metadata": {
    "id": "d474019b"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=1, n_steps=num_rollout_steps,\n",
    "            learning_rate=lr, gamma=gamma, tensorboard_log=tensorboard_log, n_epochs=n_epochs,\n",
    "            clip_range=clip_schedule, batch_size=batch_size, seed=seed, gae_lambda=gae_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4f05d",
   "metadata": {
    "id": "53754180"
   },
   "source": [
    "### Defining Callbacks\n",
    "\n",
    "We can additionally define callbacks to save model checkpoints and evaluate models during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de25d1a",
   "metadata": {
    "id": "f19803ea"
   },
   "outputs": [],
   "source": [
    "callback_list = []\n",
    "\n",
    "# Save Model Periodically\n",
    "save_freq = 10000\n",
    "save_path = '/content/drive/MyDrive/Colab Notebooks/l5kit/logs/'+ str(datetime.date.today())\n",
    "output = 'PPO'\n",
    "checkpoint_callback = CheckpointCallback(save_freq=(save_freq // train_envs), save_path=save_path, \\\n",
    "                                         name_prefix=output)\n",
    "callback_list.append(checkpoint_callback)\n",
    "\n",
    "# Eval Model Periodically\n",
    "eval_freq = 10000\n",
    "n_eval_episodes = 1\n",
    "val_eval_callback = L5KitEvalCallback(eval_env, eval_freq=(eval_freq // train_envs), \\\n",
    "                                      n_eval_episodes=n_eval_episodes, n_eval_envs=eval_envs)\n",
    "callback_list.append(val_eval_callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493a346",
   "metadata": {
    "id": "ad3bda21"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd2c799",
   "metadata": {
    "id": "2Rcvlddp8ppQ"
   },
   "outputs": [],
   "source": [
    "outdir = '/content/drive/MyDrive/Colab Notebooks/l5kit/ppo_interrupted/'+ str(datetime.date.today()) + '/'\n",
    "model_name = 'PPO'\n",
    "try:\n",
    "    n_steps = 1000000\n",
    "    model.learn(n_steps, callback=callback_list)\n",
    "except:\n",
    "    model.save(outdir + model_name)\n",
    "    # model.save_replay_buffer(outdir + model_name+ \"_buffer\")\n",
    "    model.policy.save(outdir + model_name + \"_policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c131c",
   "metadata": {
    "id": "575327a2"
   },
   "source": [
    "**Voila!** We have a trained PPO policy! Train for larger number of steps for better accuracy. Typical RL algorithms require training atleast 1M steps for good convergence. You can visualize the quantitiative evaluation using tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8a9e5",
   "metadata": {
    "id": "CFi-_Iioi_Z7"
   },
   "outputs": [],
   "source": [
    "model = PPO.load('/content/drive/MyDrive/Colab Notebooks/l5kit/ppo_interrupted/PPO2022-11-16.zip', env = env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb64bb",
   "metadata": {
    "id": "087f4e09"
   },
   "outputs": [],
   "source": [
    "model = PPO.load('/content/drive/MyDrive/Colab Notebooks/l5kit/logs/2022-11-25/PPO_4490000_steps.zip', env = env)\n",
    "n_steps = 1000000\n",
    "# model = PPO.load('./PPO_100000_steps.zip', env = env)\n",
    "model.learn(n_steps, callback=callback_list, reset_num_timesteps=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d5b7dc",
   "metadata": {
    "id": "d24f956c"
   },
   "source": [
    "### Visualize the episode from the environment\n",
    "\n",
    "We can easily visualize the outputs obtained by rolling out episodes in the L5Kit using the Bokeh visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a92ed5",
   "metadata": {
    "id": "2QQNhRPJ2bKm"
   },
   "outputs": [],
   "source": [
    "model = PPO.load('/content/drive/MyDrive/Colab Notebooks/l5kit/logs/2022-11-23/PPO_4210000_steps.zip', env = env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41dcf8-0d38-4212-8126-4c5c3cfef593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on episodes of length 32 time steps\n",
    "train_eps_length = 32\n",
    "train_envs = 4\n",
    "\n",
    "# Evaluate on entire scene (~248 time steps)\n",
    "eval_eps_length = None\n",
    "eval_envs = 1\n",
    "\n",
    "# make train env\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = 32 + 1\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "env = make_vec_env(\"L5-CLE-v0\", env_kwargs=env_kwargs, n_envs=train_envs,\n",
    "                   vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"fork\"})\n",
    "\n",
    "# make eval env\n",
    "validation_sim_cfg = SimulationConfigGym()\n",
    "validation_sim_cfg.num_simulation_steps = None\n",
    "eval_env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, \\\n",
    "                   'return_info': True, 'train': False, 'sim_cfg': validation_sim_cfg}\n",
    "eval_env = make_vec_env(\"L5-CLE-v0\", env_kwargs=eval_env_kwargs, n_envs=eval_envs,\n",
    "                        vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"fork\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25991944",
   "metadata": {
    "id": "fcd2b424"
   },
   "outputs": [],
   "source": [
    "rollout_sim_cfg = SimulationConfigGym()\n",
    "rollout_sim_cfg.num_simulation_steps = None\n",
    "rollout_env = gym.make(\"L5-CLE-v0\", env_config_path=env_config_path, sim_cfg=rollout_sim_cfg, \\\n",
    "                       use_kinematic=True, train=False, return_info=True)\n",
    "\n",
    "def rollout_episode(model, env, idx = 0):\n",
    "    \"\"\"Rollout a particular scene index and return the simulation output.\n",
    "\n",
    "    :param model: the RL policy\n",
    "    :param env: the gym environment\n",
    "    :param idx: the scene index to be rolled out\n",
    "    :return: the episode output of the rolled out scene\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the reset_scene_id to 'idx'\n",
    "    env.reset_scene_id = idx\n",
    "    \n",
    "    # Rollout step-by-step\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while True:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, _, done, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # The episode outputs are present in the key \"sim_outs\"\n",
    "    sim_out = info[\"sim_outs\"][0]\n",
    "    return sim_out\n",
    "\n",
    "# Rollout one episode\n",
    "# sim_out = rollout_episode(model, rollout_env)\n",
    "# Rollout 5 episodes\n",
    "sim_outs =[]\n",
    "for i in range(5):\n",
    "    sim_outs.append(rollout_episode(model, rollout_env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbc2c9",
   "metadata": {
    "id": "7e383cff"
   },
   "outputs": [],
   "source": [
    "# might change with different rasterizer\n",
    "map_API = rollout_env.dataset.rasterizer.sem_rast.mapAPI\n",
    "\n",
    "def visualize_outputs(sim_outs, map_API):\n",
    "    for sim_out in sim_outs: # for each scene\n",
    "        vis_in = episode_out_to_visualizer_scene_gym_cle(sim_out, map_API)\n",
    "        show(visualize(sim_out.scene_id, vis_in))\n",
    "\n",
    "output_notebook()\n",
    "visualize_outputs(sim_outs, map_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda4321",
   "metadata": {
    "id": "DjpS1pIZJ0B-"
   },
   "source": [
    "## Calculate the performance metrics from the episode outputs\n",
    "\n",
    "We can also calculate the various quantitative metrics on the rolled out episode output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa210d82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6M1kUv8_J3X7",
    "outputId": "5eba9295-94de-404d-9469-329856bd9384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+\n",
      "| scene_id |   FDE    |   ADE   |\n",
      "+----------+----------+---------+\n",
      "|    18    | 123.9884 | 58.2833 |\n",
      "|    76    | 94.0163  | 62.4942 |\n",
      "|    80    | 95.1473  | 20.5979 |\n",
      "|    11    | 25.0332  | 18.1672 |\n",
      "|    16    | 80.5144  |  31.691 |\n",
      "| Overall  | 83.7399  | 38.2467 |\n",
      "+----------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "def quantify_outputs(sim_outs, metric_set=None):\n",
    "    metric_set = metric_set if metric_set is not None else L2DisplacementYawMetricSet()\n",
    "\n",
    "    metric_set.evaluate(sim_outs)\n",
    "    scene_results = metric_set.evaluator.scene_metric_results\n",
    "    fields = [\"scene_id\", \"FDE\", \"ADE\"]\n",
    "    table = PrettyTable(field_names=fields)\n",
    "    tot_fde = 0.0\n",
    "    tot_ade = 0.0\n",
    "    for scene_id in scene_results:\n",
    "        scene_metrics = scene_results[scene_id]\n",
    "        ade_error = scene_metrics[\"displacement_error_l2\"][1:].mean()\n",
    "        fde_error = scene_metrics['displacement_error_l2'][-1]\n",
    "        table.add_row([scene_id, round(fde_error.item(), 4), round(ade_error.item(), 4)])\n",
    "        tot_fde += fde_error.item()\n",
    "        tot_ade += ade_error.item()\n",
    "\n",
    "    ave_fde = tot_fde / len(scene_results)\n",
    "    ave_ade = tot_ade / len(scene_results)\n",
    "    table.add_row([\"Overall\", round(ave_fde, 4), round(ave_ade, 4)])\n",
    "    print(table)\n",
    "\n",
    "\n",
    "quantify_outputs(sim_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ebaac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovwnSl6RJx7t",
    "outputId": "972861d0-0929-43ea-ece0-c12cb9698ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+---------+-----+-----+-----+----------+\n",
      "| scene_id |   FDE    |   ADE   |   DRT   |  CF |  CR |  CS |   PEGO   |\n",
      "+----------+----------+---------+---------+-----+-----+-----+----------+\n",
      "|    18    | 123.9884 | 58.2833 |  14.79  | 0.0 | 0.0 | 0.0 | -3.0587  |\n",
      "|    76    | 94.0163  | 62.4942 |  4.3439 | 0.0 | 0.0 | 0.0 |  2.7008  |\n",
      "|    80    | 95.1473  | 20.5979 |  4.7899 | 0.0 | 0.0 | 0.0 | -13.0379 |\n",
      "|    11    | 25.0332  | 18.1672 |  3.202  | 0.0 | 0.0 | 0.0 |  0.678   |\n",
      "|    16    | 80.5144  |  31.691 | 22.2307 | 0.0 | 0.0 | 0.0 |  0.138   |\n",
      "| Overall  | 83.7399  | 38.2467 |  9.8713 | 0.0 | 0.0 | 0.0 |  -2.516  |\n",
      "+----------+----------+---------+---------+-----+-----+-----+----------+\n"
     ]
    }
   ],
   "source": [
    "def quantify_outputs(sim_outs, metric_set=None):\n",
    "    metric_set = metric_set if metric_set is not None else CLEMetricSet()\n",
    "\n",
    "    metric_set.evaluate(sim_outs)\n",
    "    scene_results = metric_set.evaluator.scene_metric_results\n",
    "    fields = [\"scene_id\", \"FDE\", \"ADE\", \"DRT\", \"CF\", \"CR\", \"CS\", \"PEGO\"]\n",
    "    table = PrettyTable(field_names=fields)\n",
    "    tot_fde = 0.0\n",
    "    tot_ade = 0.0\n",
    "    tot_drt = 0.0\n",
    "    tot_cf = 0.0\n",
    "    tot_cr = 0.0\n",
    "    tot_cs = 0.0\n",
    "    tot_p_ego = 0.0\n",
    "    tot_a_ego = 0.0\n",
    "    # print(scene_results[0])\n",
    "    for scene_id in scene_results:\n",
    "        scene_metrics = scene_results[scene_id]\n",
    "        ade_error = scene_metrics[\"displacement_error_l2\"][1:].mean()\n",
    "        fde_error = scene_metrics['displacement_error_l2'][-1]\n",
    "        drt_error = scene_metrics['distance_to_reference_trajectory'][-1]\n",
    "        cf_error = scene_metrics['collision_front'][-1]\n",
    "        cr_error = scene_metrics['collision_rear'][-1]\n",
    "        cs_error = scene_metrics['collision_side'][-1]\n",
    "        p_ego = scene_metrics['simulated_minus_recorded_ego_speed'][-1]\n",
    "        # a_ego = scene_metrics['aggressive_ego'][-1]\n",
    "        table.add_row([scene_id, round(fde_error.item(), 4), round(ade_error.item(), 4), round(drt_error.item(), 4), round(cf_error.item(), 4), round(cr_error.item(), 4), \n",
    "        round(cs_error.item(), 4), round(p_ego.item(), 4)])\n",
    "        tot_fde += fde_error.item()\n",
    "        tot_ade += ade_error.item()\n",
    "        tot_drt += drt_error.item()\n",
    "        tot_cf += cf_error.item()\n",
    "        tot_cr += cr_error.item()\n",
    "        tot_cs += cs_error.item()\n",
    "        tot_p_ego += p_ego.item()\n",
    "        # tot_a_ego += a_ego.item()\n",
    "\n",
    "    ave_fde = tot_fde / len(scene_results)\n",
    "    ave_ade = tot_ade / len(scene_results)\n",
    "    ave_drt = tot_drt / len(scene_results)\n",
    "    ave_cf = tot_cf / len(scene_results)\n",
    "    ave_cr = tot_cr / len(scene_results)\n",
    "    ave_cs = tot_cs / len(scene_results)\n",
    "    ave_p_ego = tot_p_ego / len(scene_results)\n",
    "    # ave_a_ego = tot_a_ego / len(scene_results)\n",
    "    table.add_row([\"Overall\", round(ave_fde, 4), round(ave_ade, 4), round(ave_drt, 4), round(ave_cf, 4), round(ave_cr, 4), round(ave_cs, 4), round(ave_p_ego, 4)])\n",
    "    print(table)\n",
    "\n",
    "\n",
    "quantify_outputs(sim_outs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Fag3VuhPnRZT",
    "xHfH5HGWoTD7",
    "eBwt9neMoj9h",
    "0CAZm9UDo1C0"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6df7c2a3d813445d6b3c74a479f8d37af444dbb4628cead36b7b0d6872de20bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
