{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f64953",
   "metadata": {
    "id": "f7f64953"
   },
   "source": [
    "### Training RL Policies using L5Kit Closed-Loop Environment\n",
    "\n",
    "This notebook describes how to train RL policies for self-driving using our gym-compatible closed-loop environment.\n",
    "\n",
    "We will be using [Proximal Policy Optimization (PPO)](https://arxiv.org/abs/1707.06347) algorithm as our reinforcement learning algorithm, as it not only demonstrates remarkable performance but it is also empirically easy to tune.\n",
    "\n",
    "The PPO implementation in this notebook is based on [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3) framework, a popular framework for training RL policies. Note that our environment is also compatible with [RLlib](https://docs.ray.io/en/latest/rllib.html), another popular frameworks for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8M93dR9mSbS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8M93dR9mSbS",
    "outputId": "ea59baac-c935-472e-90ba-f9680dcd64f1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806093d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "806093d7",
    "outputId": "1485289a-f6c5-4d30-bceb-a20a9a1a3e5f"
   },
   "outputs": [],
   "source": [
    "#@title Download L5 Sample Dataset and install L5Kit\n",
    "import os\n",
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "if RunningInCOLAB:\n",
    "    !wget https://raw.githubusercontent.com/lyft/l5kit/master/examples/setup_notebook_colab.sh -q\n",
    "    !sh ./setup_notebook_colab.sh\n",
    "    os.environ[\"L5KIT_DATA_FOLDER\"] = open(\"./dataset_dir.txt\", \"r\").read().strip()\n",
    "else:\n",
    "    os.environ[\"L5KIT_DATA_FOLDER\"] = \"/home/pronton/rl/l5kit_dataset/\"\n",
    "    print(\"Not running in Google Colab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2GZXzzJ48Q2i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GZXzzJ48Q2i",
    "outputId": "9bd0d752-a7b3-4c6c-d769-4631d5866064"
   },
   "outputs": [],
   "source": [
    "# !pip install stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b1fe7",
   "metadata": {
    "id": "585b1fe7"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import get_linear_fn\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.environment.feature_extractor import CustomFeatureExtractor\n",
    "from l5kit.environment.callbacks import L5KitEvalCallback\n",
    "from l5kit.environment.envs.l5_env import SimulationConfigGym\n",
    "\n",
    "from l5kit.visualization.visualizer.zarr_utils import episode_out_to_visualizer_scene_gym_cle\n",
    "from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from bokeh.io import output_notebook, show\n",
    "from l5kit.environment.gym_metric_set import L2DisplacementYawMetricSet, CLEMetricSet\n",
    "from prettytable import PrettyTable\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea81f77",
   "metadata": {
    "id": "2ea81f77"
   },
   "outputs": [],
   "source": [
    "# Dataset is assumed to be on the folder specified\n",
    "# in the L5KIT_DATA_FOLDER environment variable\n",
    "\n",
    "# get environment config\n",
    "env_config_path = '/home/pronton/rl/l5kit/examples/RL/gg colabs/gym_config.yaml'\n",
    "cfg = load_config_data(env_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_sim_cfg = SimulationConfigGym()\n",
    "rollout_sim_cfg.num_simulation_steps = None\n",
    "rollout_env = gym.make(\"L5-CLE-v0\", env_config_path=env_config_path, sim_cfg=rollout_sim_cfg, \\\n",
    "                       use_kinematic=True, train=False, return_info=True)\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cead394",
   "metadata": {
    "id": "2cead394"
   },
   "source": [
    "### Define Training and Evaluation Environments\n",
    "\n",
    "**Training**: We will be training the PPO policy on episodes of length 32 time-steps. We will have 4 sub-processes (training environments) that will help to parallelize and speeden up episode rollouts. The *SimConfig* dataclass will define the parameters of the episode rollout: like length of episode rollout, whether to use log-replayed agents or simulated agents etc.\n",
    "\n",
    "**Evaluation**: We will evaluate the performance of the PPO policy on the *entire* scene (~248 time-steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c8313",
   "metadata": {
    "id": "b04c8313"
   },
   "outputs": [],
   "source": [
    "# Train on episodes of length 32 time steps\n",
    "train_eps_length = 32\n",
    "train_envs = 4\n",
    "\n",
    "# Evaluate on entire scene (~248 time steps)\n",
    "eval_eps_length = None\n",
    "eval_envs = 1\n",
    "\n",
    "# make train env\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "env = make_vec_env(\"L5-CLE-v0\", env_kwargs=env_kwargs, n_envs=train_envs,\n",
    "                   vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"fork\"})\n",
    "\n",
    "# make eval env\n",
    "validation_sim_cfg = SimulationConfigGym()\n",
    "validation_sim_cfg.num_simulation_steps = None\n",
    "eval_env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, \\\n",
    "                   'return_info': True, 'train': False, 'sim_cfg': validation_sim_cfg}\n",
    "eval_env = make_vec_env(\"L5-CLE-v0\", env_kwargs=eval_env_kwargs, n_envs=eval_envs,\n",
    "                        vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"fork\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522bda43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l5kit.environment.envs.l5_env import GymStepOutput, SimulationConfigGym, L5Env\n",
    "import numpy as np\n",
    "env = L5Env(**env_kwargs)\n",
    "env.reset()\n",
    "done = False\n",
    "while True:\n",
    "    # action = np.array(env.action_space.sample())\n",
    "    action = np.array(env.action_space.sample())\n",
    "    obs, r, done, info = env.step(action)\n",
    "    print(obs, r, action)\n",
    "    break\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc8b1a",
   "metadata": {
    "id": "9dfc8b1a"
   },
   "source": [
    "### Define backbone feature extractor\n",
    "\n",
    "The backbone feature extractor is shared between the policy and the value networks. The feature extractor *simple_gn* is composed of two convolutional networks followed by a fully connected layer, with ReLU activation. The feature extractor output is passed to both the policy and value networks composed of two fully connected layers with tanh activation (SB3 default).\n",
    "\n",
    "We perform **group normalization** after every convolutional layer. Empirically, we found that group normalization performs far superior to batch normalization. This can be attributed to the fact that activation statistics change quickly in on-policy algorithms (PPO is on-policy) while batch-norm learnable parameters can be slow to update causing training issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5ac39",
   "metadata": {
    "id": "4da5ac39"
   },
   "outputs": [],
   "source": [
    "# A simple 2 Layer CNN architecture with group normalization\n",
    "model_arch = 'simple_gn'\n",
    "features_dim = 128\n",
    "\n",
    "# Custom Feature Extractor backbone\n",
    "policy_kwargs = {\n",
    "    \"features_extractor_class\": CustomFeatureExtractor,\n",
    "    \"features_extractor_kwargs\": {\"features_dim\": features_dim, \"model_arch\": model_arch},\n",
    "    \"normalize_images\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ec4f23",
   "metadata": {
    "id": "24ec4f23"
   },
   "source": [
    "### Clipping Schedule\n",
    "\n",
    "We linearly decrease the value of the clipping parameter $\\epsilon$ as the PPO training progress as it shows improved training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28b605",
   "metadata": {
    "id": "dc28b605"
   },
   "outputs": [],
   "source": [
    "# Clipping schedule of PPO epsilon parameter\n",
    "start_val = 0.1\n",
    "end_val = 0.01\n",
    "training_progress_ratio = 1.0\n",
    "clip_schedule = get_linear_fn(start_val, end_val, training_progress_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596deb6",
   "metadata": {
    "id": "8596deb6"
   },
   "source": [
    "### Hyperparameters for PPO. \n",
    "\n",
    "For detailed description, refer https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/ppo/ppo.html#PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a927f",
   "metadata": {
    "id": "998a927f"
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "num_rollout_steps = 256\n",
    "gamma = 0.8\n",
    "gae_lambda = 0.9\n",
    "n_epochs = 10\n",
    "seed = 42\n",
    "batch_size = 64\n",
    "tensorboard_log = '/content/drive/MyDrive/Colab Notebooks/tb_logs/' + str(datetime.date.today()) + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310190e",
   "metadata": {
    "id": "a310190e"
   },
   "source": [
    "### Define the PPO Policy.\n",
    "\n",
    "SB3 provides an easy interface to the define the PPO policy. Note: We do need to tweak appropriate hyperparameters and the custom policy backbone has been defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474019b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d474019b",
    "outputId": "0cd173d9-fa51-4ed7-cd51-e2c02e517a56"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = PPO(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=1, n_steps=num_rollout_steps,\n",
    "            learning_rate=lr, gamma=gamma, tensorboard_log=tensorboard_log, n_epochs=n_epochs,\n",
    "            clip_range=clip_schedule, batch_size=batch_size, seed=seed, gae_lambda=gae_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53754180",
   "metadata": {
    "id": "53754180"
   },
   "source": [
    "### Defining Callbacks\n",
    "\n",
    "We can additionally define callbacks to save model checkpoints and evaluate models during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19803ea",
   "metadata": {
    "id": "f19803ea"
   },
   "outputs": [],
   "source": [
    "callback_list = []\n",
    "\n",
    "# Save Model Periodically\n",
    "save_freq = 10000\n",
    "save_path = '/content/drive/MyDrive/Colab Notebooks/logs/'\n",
    "output = 'PPO'\n",
    "checkpoint_callback = CheckpointCallback(save_freq=(save_freq // train_envs), save_path=save_path, \\\n",
    "                                         name_prefix=output)\n",
    "callback_list.append(checkpoint_callback)\n",
    "\n",
    "# Eval Model Periodically\n",
    "eval_freq = 10000\n",
    "n_eval_episodes = 1\n",
    "val_eval_callback = L5KitEvalCallback(eval_env, eval_freq=(eval_freq // train_envs), \\\n",
    "                                      n_eval_episodes=n_eval_episodes, n_eval_envs=eval_envs)\n",
    "callback_list.append(val_eval_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1000000\n",
    "model.learn(n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3bda21",
   "metadata": {
    "id": "ad3bda21"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Rcvlddp8ppQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Rcvlddp8ppQ",
    "outputId": "6a0e17e9-1bea-46f9-fb84-08d2cd24aa31",
    "tags": []
   },
   "outputs": [],
   "source": [
    "outdir = '/content/drive/MyDrive/Colab Notebooks/ppo_interrupted/'\n",
    "model_name = 'PPO'+ str(datetime.date.today())\n",
    "try:\n",
    "    n_steps = 1000000\n",
    "    model.learn(n_steps, callback=callback_list)\n",
    "except:\n",
    "    model.save(outdir + model_name)\n",
    "    # model.save_replay_buffer(outdir + model_name+ \"_buffer\")\n",
    "    model.policy.save(outdir + model_name + \"_policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575327a2",
   "metadata": {
    "id": "575327a2"
   },
   "source": [
    "**Voila!** We have a trained PPO policy! Train for larger number of steps for better accuracy. Typical RL algorithms require training atleast 1M steps for good convergence. You can visualize the quantitiative evaluation using tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CFi-_Iioi_Z7",
   "metadata": {
    "id": "CFi-_Iioi_Z7"
   },
   "outputs": [],
   "source": [
    "model = PPO.load('/home/pronton/rl/l5kit/examples/RL/gg colabs/logs/PPO_5410000_steps.zip', env = env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f956c",
   "metadata": {
    "id": "d24f956c"
   },
   "source": [
    "### Visualize the episode from the environment\n",
    "\n",
    "We can easily visualize the outputs obtained by rolling out episodes in the L5Kit using the Bokeh visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2b424",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcd2b424",
    "outputId": "da2951ba-fcf3-49d1-f975-597cf66b02cc"
   },
   "outputs": [],
   "source": [
    "rollout_sim_cfg = SimulationConfigGym()\n",
    "rollout_sim_cfg.num_simulation_steps = None\n",
    "rollout_env = gym.make(\"L5-CLE-v0\", env_config_path=env_config_path, sim_cfg=rollout_sim_cfg, \\\n",
    "                       use_kinematic=True, train=False, return_info=True)\n",
    "\n",
    "def rollout_episode(model, env, idx = 0):\n",
    "    \"\"\"Rollout a particular scene index and return the simulation output.\n",
    "\n",
    "    :param model: the RL policy\n",
    "    :param env: the gym environment\n",
    "    :param idx: the scene index to be rolled out\n",
    "    :return: the episode output of the rolled out scene\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the reset_scene_id to 'idx'\n",
    "    env.set_reset_id(idx)\n",
    "    \n",
    "    # Rollout step-by-step\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while True:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, _, done, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # The episode outputs are present in the key \"sim_outs\"\n",
    "    sim_out = info[\"sim_outs\"][0]\n",
    "    return sim_out\n",
    "\n",
    "# Rollout one episode\n",
    "# sim_out = rollout_episode(model, rollout_env)\n",
    "# Rollout 5 episodes\n",
    "sim_outs =[]\n",
    "for i in range(2):\n",
    "    sim_outs.append(rollout_episode(model, rollout_env, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e383cff",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "7e383cff",
    "outputId": "5c1c4be2-9d37-4061-88e8-1f9985edb93a"
   },
   "outputs": [],
   "source": [
    "# might change with different rasterizer\n",
    "map_API = rollout_env.dataset.rasterizer.sem_rast.mapAPI\n",
    "\n",
    "def visualize_outputs(sim_outs, map_API):\n",
    "    for sim_out in sim_outs: # for each scene\n",
    "        vis_in = episode_out_to_visualizer_scene_gym_cle(sim_out, map_API)\n",
    "        show(visualize(sim_out.scene_id, vis_in))\n",
    "\n",
    "output_notebook()\n",
    "visualize_outputs(sim_outs, map_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e522ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoDataset, AgentDataset\n",
    "\n",
    "from l5kit.visualization.visualizer.zarr_utils import zarr_to_visualizer_scene\n",
    "from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from l5kit.data import MapAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fccfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = LocalDataManager()\n",
    "dataset_path = dm.require(cfg[\"val_data_loader\"][\"key\"])\n",
    "zarr_dataset = ChunkedDataset(dataset_path)\n",
    "zarr_dataset.open()\n",
    "print(zarr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a792b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.dataset import EgoDataset\n",
    "rast = build_rasterizer(cfg, LocalDataManager(\"/home/pronton/rl/l5kit_dataset/\"))\n",
    "\n",
    "dataset = EgoDataset(cfg, zarr_dataset, rast)\n",
    "for data in dataset:  # this iterates over frames under the hood\n",
    "    print('target_positions:' + str(data[\"target_positions\"]))\n",
    "    print('target_yaws:' + str(data[\"target_yaws\"]))\n",
    "    print('history_positions:' + str(data[\"history_positions\"]))\n",
    "    print('history_yaws:' + str(data[\"history_yaws\"]))\n",
    "    print('centroid:' + str(data[\"centroid\"]))\n",
    "    print('yaw:' + str(data[\"yaw\"]))\n",
    "    print('extent:' + str(data[\"extent\"]))\n",
    "   \n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e790d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "mapAPI = MapAPI.from_cfg(dm, cfg)\n",
    "for scene_idx in range(2):\n",
    "    out = zarr_to_visualizer_scene(zarr_dataset.get_scene_dataset(scene_idx), mapAPI)\n",
    "    out_vis = visualize(scene_idx, out)\n",
    "    show(out_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DjpS1pIZJ0B-",
   "metadata": {
    "id": "DjpS1pIZJ0B-"
   },
   "source": [
    "## Calculate the performance metrics from the episode outputs\n",
    "\n",
    "We can also calculate the various quantitative metrics on the rolled out episode output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6M1kUv8_J3X7",
   "metadata": {
    "id": "6M1kUv8_J3X7"
   },
   "outputs": [],
   "source": [
    "def quantify_outputs(sim_outs, metric_set=None):\n",
    "    metric_set = metric_set if metric_set is not None else L2DisplacementYawMetricSet()\n",
    "\n",
    "    metric_set.evaluate(sim_outs)\n",
    "    scene_results = metric_set.evaluator.scene_metric_results\n",
    "    fields = [\"scene_id\", \"FDE\", \"ADE\"]\n",
    "    table = PrettyTable(field_names=fields)\n",
    "    tot_fde = 0.0\n",
    "    tot_ade = 0.0\n",
    "    for scene_id in scene_results:\n",
    "        scene_metrics = scene_results[scene_id]\n",
    "        ade_error = scene_metrics[\"displacement_error_l2\"][1:].mean()\n",
    "        fde_error = scene_metrics['displacement_error_l2'][-1]\n",
    "        table.add_row([scene_id, round(fde_error.item(), 4), round(ade_error.item(), 4)])\n",
    "        tot_fde += fde_error.item()\n",
    "        tot_ade += ade_error.item()\n",
    "\n",
    "    ave_fde = tot_fde / len(scene_results)\n",
    "    ave_ade = tot_ade / len(scene_results)\n",
    "    table.add_row([\"Overall\", round(ave_fde, 4), round(ave_ade, 4)])\n",
    "    print(table)\n",
    "\n",
    "\n",
    "quantify_outputs(sim_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ovwnSl6RJx7t",
   "metadata": {
    "id": "ovwnSl6RJx7t"
   },
   "outputs": [],
   "source": [
    "def quantify_outputs(sim_outs, metric_set=None):\n",
    "    metric_set = metric_set if metric_set is not None else CLEMetricSet()\n",
    "\n",
    "    metric_set.evaluate(sim_outs)\n",
    "    scene_results = metric_set.evaluator.scene_metric_results\n",
    "    fields = [\"scene_id\", \"FDE\", \"ADE\", \"DRT\", \"CF\", \"CR\", \"CS\", \"passive (<5), aggressive(>5) \"]\n",
    "    table = PrettyTable(field_names=fields)\n",
    "    tot_fde = 0.0\n",
    "    tot_ade = 0.0\n",
    "    tot_drt = 0.0\n",
    "    tot_cf = 0.0\n",
    "    tot_cr = 0.0\n",
    "    tot_cs = 0.0\n",
    "    tot_p_ego = 0.0\n",
    "    tot_a_ego = 0.0\n",
    "    # print(scene_results[0])\n",
    "    for scene_id in scene_results:\n",
    "        scene_metrics = scene_results[scene_id]\n",
    "        ade_error = scene_metrics[\"displacement_error_l2\"][1:].mean()\n",
    "        fde_error = scene_metrics['displacement_error_l2'][-1]\n",
    "        drt_error = scene_metrics['distance_to_reference_trajectory'][-1]\n",
    "        cf_error = scene_metrics['collision_front'][-1]\n",
    "        cr_error = scene_metrics['collision_rear'][-1]\n",
    "        cs_error = scene_metrics['collision_side'][-1]\n",
    "        p_ego = scene_metrics['simulated_minus_recorded_ego_speed'][-1]\n",
    "        # a_ego = scene_metrics['aggressive_ego'][-1]\n",
    "        table.add_row([scene_id, round(fde_error.item(), 4), round(ade_error.item(), 4), round(drt_error.item(), 4), round(cf_error.item(), 4), round(cr_error.item(), 4), \n",
    "        round(cs_error.item(), 4), round(p_ego.item(), 4)])\n",
    "        tot_fde += fde_error.item()\n",
    "        tot_ade += ade_error.item()\n",
    "        tot_drt += drt_error.item()\n",
    "        tot_cf += cf_error.item()\n",
    "        tot_cr += cr_error.item()\n",
    "        tot_cs += cs_error.item()\n",
    "        tot_p_ego += p_ego.item()\n",
    "        # tot_a_ego += a_ego.item()\n",
    "\n",
    "    ave_fde = tot_fde / len(scene_results)\n",
    "    ave_ade = tot_ade / len(scene_results)\n",
    "    ave_drt = tot_drt / len(scene_results)\n",
    "    ave_cf = tot_cf / len(scene_results)\n",
    "    ave_cr = tot_cr / len(scene_results)\n",
    "    ave_cs = tot_cs / len(scene_results)\n",
    "    ave_p_ego = tot_p_ego / len(scene_results)\n",
    "    # ave_a_ego = tot_a_ego / len(scene_results)\n",
    "    table.add_row([\"Overall\", round(ave_fde, 4), round(ave_ade, 4), round(ave_drt, 4), round(ave_cf, 4), round(ave_cr, 4), round(ave_cs, 4), round(ave_p_ego, 4)])\n",
    "    print(table)\n",
    "\n",
    "\n",
    "quantify_outputs(sim_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_junction(elem, map_api):\n",
    "    return elem.element.HasField(\"junction\")\n",
    "\n",
    "def get_junctions(map_api):\n",
    "    return [elem for elem in map_api.elements if is_junction(elem, map_api)]\n",
    "\n",
    "all_junctions = get_junctions(mapAPI)\n",
    "all_junctions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc60502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_segment(elem, map_api):\n",
    "    return elem.element.HasField(\"segment\")\n",
    "\n",
    "def get_segments(map_api):\n",
    "    return [elem for elem in map_api.elements if is_segment(elem, map_api)]\n",
    "\n",
    "all_segments = get_segments(mapAPI)\n",
    "all_segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_annotated_shape(elem, map_api):\n",
    "    return elem.element.HasField(\"annotated_shape\")\n",
    "\n",
    "def get_annotated_shapes(map_api):\n",
    "    return [elem for elem in map_api.elements if is_annotated_shape(elem, map_api)]\n",
    "\n",
    "all_annotated_shapes = get_annotated_shapes(mapAPI)\n",
    "all_annotated_shapes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f4e09",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "087f4e09"
   },
   "outputs": [],
   "source": [
    "# model = PPO.load('/content/PPO_630000_steps.zip', env = env)\n",
    "# n_steps = 1000000\n",
    "# # model = PPO.load('./PPO_100000_steps.zip', env = env)\n",
    "# model.learn(n_steps, callback=callback_list, reset_num_timesteps=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "MAP_LAYERS = [\"junction\", \"node\", \"segment\", \"lane\"]\n",
    "\n",
    "\n",
    "def element_of_type(elem, layer_name):\n",
    "    return elem.element.HasField(layer_name)\n",
    "\n",
    "\n",
    "def get_elements_from_layer(map_api, layer_name):\n",
    "    return [elem for elem in map_api.elements if element_of_type(elem, layer_name)]\n",
    "\n",
    "\n",
    "class MapRenderer:\n",
    "    \n",
    "    def __init__(self, map_api):\n",
    "        self._color_map = dict(drivable_area='#a6cee3',\n",
    "                               road_segment='#1f78b4',\n",
    "                               road_block='#b2df8a',\n",
    "                               lane='#474747')\n",
    "        self._map_api = map_api\n",
    "    \n",
    "    def render_layer(self, layer_name):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_axes([0, 0, 1, 1])\n",
    "        \n",
    "    def render_lanes(self):\n",
    "        all_lanes = get_elements_from_layer(self._map_api, \"lane\")\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_axes([0, 0, 1, 1])\n",
    "        for lane in all_lanes:\n",
    "            self.render_lane(ax, lane)\n",
    "        return fig, ax\n",
    "        \n",
    "    def render_lane(self, ax, lane):\n",
    "        coords = self._map_api.get_lane_coords(MapAPI.id_as_str(lane.id))\n",
    "        self.render_boundary(ax, coords[\"xyz_left\"])\n",
    "        self.render_boundary(ax, coords[\"xyz_right\"])\n",
    "        \n",
    "    def render_boundary(self, ax, boundary):\n",
    "        xs = boundary[:, 0]\n",
    "        ys = boundary[:, 1] \n",
    "        ax.plot(xs, ys, color=self._color_map[\"lane\"], label=\"lane\")\n",
    "renderer = MapRenderer(mapAPI)\n",
    "fig, ax = renderer.render_lanes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_df = pd.DataFrame(scenes)\n",
    "scenes_df[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "scenes = zarr_dataset.scenes\n",
    "scenes_df = pd.DataFrame(scenes)\n",
    "scenes_df.columns = [\"data\"]; features = ['frame_index_interval', 'host', 'start_time', 'end_time', ]\n",
    "for i, feature in enumerate(features):\n",
    "    scenes_df[feature] = scenes_df['data'].apply(lambda x: x[i])\n",
    "scenes_df.drop(columns=[\"data\"],inplace=True)\n",
    "print(f\"scenes dataset: {scenes_df.shape}\")\n",
    "scenes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f2a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "colormap = plt.cm.magma\n",
    "cont_feats = [\"centroid_x\", \"centroid_y\", \"extent_x\", \"extent_y\", \"extent_z\", \"yaw\"]\n",
    "plt.figure(figsize=(16,12));\n",
    "plt.title('Pearson correlation of features', y=1.05, size=15);\n",
    "sns.heatmap(agents[cont_feats].corr(),linewidths=0.1,vmax=1.0, square=True, \n",
    "            cmap=colormap, linecolor='white', annot=True);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "l5kit-nr_j5XnQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6df7c2a3d813445d6b3c74a479f8d37af444dbb4628cead36b7b0d6872de20bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
