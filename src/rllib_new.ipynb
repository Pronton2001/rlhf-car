{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from l5kit.data.map_api import MapAPI\n",
    "# from l5kit.environment.envs.l5_env import GymStepOutput, SimulationConfigGym\n",
    "from l5kit.environment.envs.l5_env2 import GymStepOutput, SimulationConfigGym, L5Env2\n",
    "from l5kit.environment.envs.l5_env import GymStepOutput, SimulationConfigGym, L5Env\n",
    "# Dataset is assumed to be on the folder specified\n",
    "# in the L5KIT_DATA_FOLDER environment variable\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.tune.logger import pretty_print\n",
    "import ray.rllib.algorithms.ppo as ppo\n",
    "from ray import tune\n",
    "from ray.rllib.models import ModelCatalog\n",
    "# from wrapper import L5EnvWrapper\n",
    "# from src.customEnv.wr import wrapper\n",
    "# from customModel.customModel import TorchGNCNN, TorchAttentionModel, TorchAttentionModel2\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from tempfile import gettempdir\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoDatasetVectorized\n",
    "from l5kit.planning.vectorized.closed_loop_model import VectorizedUnrollModel\n",
    "from l5kit.planning.vectorized.open_loop_model import VectorizedModel\n",
    "from l5kit.vectorization.vectorizer_builder import build_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get environment config\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"/workspace/datasets\"\n",
    "# env_config_path = '/workspace/source/src/configs/gym_vectorizer_config.yaml'\n",
    "env_config_path = '/workspace/source/src/configs/gym_rasterizer_config.yaml'\n",
    "dmg = LocalDataManager(None)\n",
    "cfg = load_config_data(env_config_path)\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_path = \"/home/pronton/rl/l5kit/examples/urban_driver/OL_HS.pt\"\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = torch.load(model_path).to(device)\n",
    "# # model = SAC.load(\"/home/pronton/rl/l5kit/examples/RL/gg colabs/logs/SAC_640000_steps.zip\")\n",
    "# model = model.eval()\n",
    "# torch.set_grad_enabled(False)\n",
    "from customModel.customModel import TorchAttentionModel3\n",
    "from customModel.customModel import TorchRasterNet\n",
    "\n",
    "\n",
    "# os.environ[\"L5KIT_DATA_FOLDER\"] = \"/media/pronton/linux_files/a100code/l5kit/l5kit_dataset\"\n",
    "# env_config_path = '/home/pronton/rl/rlhf-car/src/configs/gym_vectorizer_config.yaml'\n",
    "dmg = LocalDataManager(None)\n",
    "cfg = load_config_data(env_config_path)\n",
    "# rollout_sim_cfg = SimulationConfigGym()\n",
    "# rollout_sim_cfg.num_simulation_steps = None\n",
    "# env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': False, 'sim_cfg': rollout_sim_cfg,  'train': False, 'return_info': True, 'rescale_action': False}\n",
    "# rollout_env = L5Env2(**env_kwargs)\n",
    "# print(rollout_env.action_space)\n",
    "# model = TorchAttentionModel3(np.zeros((112,112,7)), np.array((3,)),3, model_config= {\"custom_model_config\": {'cfg':cfg}}, name='')\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "###################### TRAINING ######################\n",
    "ModelCatalog.register_custom_model( \"TorchSeparatedAttentionModel\", TorchAttentionModel3)\n",
    "ModelCatalog.register_custom_model( \"TorchSeparatedRasterModel\", TorchRasterNet)\n",
    "from src.customEnv.wrapper import L5EnvRasterizerTorch\n",
    "from ray import tune\n",
    "import ray\n",
    "train_eps_length = 32\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': False, 'sim_cfg': train_sim_cfg, 'rescale_action': False}\n",
    "tune.register_env(\"L5-CLE-V2\", lambda config: L5Env2(**env_kwargs))\n",
    "tune.register_env(\"L5-CLE-V1\", lambda config: L5EnvRasterizerTorch(env = L5Env(**env_kwargs), \\\n",
    "                                                           raster_size= cfg['raster_params']['raster_size'][0], \\\n",
    "                                                           n_channels = 5))\n",
    "ray.init(num_cpus=4, ignore_reinit_error=True, log_to_driver=False, local_mode=True)\n",
    "algo = ppo.PPO(\n",
    "        env=\"L5-CLE-V1\", #\"L5-CLE-V2\",\n",
    "        config={\n",
    "            # 'disable_env_checking':True,\n",
    "            \"framework\": \"torch\",\n",
    "            'log_level': 'INFO',\n",
    "            'num_gpu': 0,\n",
    "            'train_batch_size': 1,\n",
    "            'sgd_minibatch_size': 1,\n",
    "            'num_sgd_iter': 1,\n",
    "            'seed': 42,\n",
    "            'batch_mode': 'truncate_episodes',\n",
    "            # \"rollout_fragment_length\": 32,\n",
    "            \"model\": {\n",
    "                \"custom_model\": \"TorchSeparatedRasterModel\", #TorchSeparatedAttentionModel\n",
    "                # Extra kwargs to be passed to your model's c'tor.\n",
    "                \"custom_model_config\": {'cfg':cfg},\n",
    "            },\n",
    "            # \"output\": \"/home/pronton/rl/l5kit/examples/RL/notebooks/logs/l5env2-out\", \n",
    "            # \"output_max_file_size\": 5000000,\n",
    "            '_disable_preprocessor_api': True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "KLPPO = 'KLPPO'\n",
    "UNROLLVECTORNET = 'UNROLLVECTORNET'\n",
    "VECTORNET = 'VECTORNET'\n",
    "def rollout_episode(model, env, idx = 0, model_type = VECTORNET):\n",
    "    \"\"\"Rollout a particular scene index and return the simulation output.\n",
    "\n",
    "    :param model: the RL policy\n",
    "    :param env: the gym environment\n",
    "    :param idx: the scene index to be rolled out\n",
    "    :return: the episode output of the rolled out scene\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the reset_scene_id to 'idx'\n",
    "    env.set_reset_id(idx)\n",
    "    \n",
    "    # Rollout step-by-step\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    rewards = []\n",
    "    while True:\n",
    "        # print(obs)\n",
    "        # action = np.array(env.action_space.sample())\n",
    "        if model_type == 'KLPPO':\n",
    "            action = model.compute_single_action(obs)\n",
    "        if model_type in ['VECTORNET', 'UNROLLNET']:\n",
    "            action = model(obs)\n",
    "        # print(action)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        # print(action)\n",
    "        # print(env.ego_output_dict)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # The episode outputs are present in the key \"sim_outs\"\n",
    "    sim_out = info[\"sim_outs\"][0]\n",
    "    return sim_out, np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_sim_cfg = SimulationConfigGym()\n",
    "rollout_sim_cfg.num_simulation_steps = None\n",
    "\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': False, 'sim_cfg': rollout_sim_cfg,  'train': False, 'return_info': True, 'rescale_action': False}\n",
    "# tune.register_env(\"L5-CLE-V0\", lambda config: L5Env(**env_kwargs))\n",
    "rollout_env = L5EnvRasterizerTorch(env = L5Env(**env_kwargs), \\\n",
    "                                                           raster_size= cfg['raster_params']['raster_size'][0], \\\n",
    "                                                           n_channels = 5)\n",
    "# rollout_env = L5Env2(**env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rollout_sim_cfg = SimulationConfigGym()\n",
    "rollout_sim_cfg.num_simulation_steps = None\n",
    "\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': False, 'sim_cfg': rollout_sim_cfg,  'train': False, 'return_info': True, 'rescale_action': False}\n",
    "# rollout_env = L5Env2(**env_kwargs)\n",
    "rollout_env = L5Env2(**env_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from l5kit.visualization.visualizer.zarr_utils import episode_out_to_visualizer_scene_gym_cle, simulation_out_to_visualizer_scene\n",
    "from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from bokeh.io import output_notebook, show\n",
    "sim_outs =[]\n",
    "rollout_sim_cfg = SimulationConfigGym()\n",
    "rollout_sim_cfg.num_simulation_steps = None\n",
    "# env_config_path = '/workspace/source/src/configs/gym_config.yaml'\n",
    "\n",
    "# env_config_path = \n",
    "# env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': False, 'sim_cfg': rollout_sim_cfg,  'train': False, 'return_info': True}\n",
    "\n",
    "# rollout_env = L5Env(**env_kwargs)\n",
    "\n",
    "# for i in range(1):\n",
    "# sim_outs.append(rollout_episode(algo, rollout_env, 82, KLPPO))\n",
    "# results = [rollout_episode(algo, rollout_env, i, KLPPO) for i in [0,20,40]]\n",
    "results = np.array([rollout_episode(algo, rollout_env, i, KLPPO) for i in [1,20,30]])\n",
    "sim_outs,rewards = results[:,0], np.array(results[:,1])\n",
    "rewards.reshape(rewards.shape[0], -1)\n",
    "print([np.sum(r) for r in rewards])\n",
    "print(rewards)\n",
    "\n",
    "# might change with different rasterizer\n",
    "mapAPI = MapAPI.from_cfg(dmg, cfg)\n",
    "\n",
    "def visualize_outputs(sim_outs, map_API):\n",
    "    for sim_out in sim_outs: # for each scene\n",
    "        vis_in = episode_out_to_visualizer_scene_gym_cle(sim_out, map_API)\n",
    "        show(visualize(sim_out.scene_id, vis_in))\n",
    "\n",
    "output_notebook()\n",
    "visualize_outputs(sim_outs, mapAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_eps_length = 10\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': False, 'sim_cfg': train_sim_cfg}\n",
    "tune.register_env(\"L5-CLE-V2\", lambda config: L5Env2(**env_kwargs))\n",
    "ray.init(num_cpus=1, ignore_reinit_error=True, log_to_driver=False)\n",
    "ModelCatalog.register_custom_model( \"TorchSeparatedAttentionModel\", TorchAttentionModel)\n",
    "ModelCatalog.register_custom_model( \"TorchSharedAttentionModel\", TorchAttentionModel2)\n",
    "ModelCatalog.register_custom_model(\"GN_CNN_torch_model\", TorchGNCNN)\n",
    "\n",
    "# Create the Trainer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L5env1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eps_length = 32\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': False, 'sim_cfg': train_sim_cfg}\n",
    "\n",
    "\n",
    "tune.register_env(\"L5-CLE-V1\", lambda config: L5EnvWrapper(L5Env(**env_kwargs)))\n",
    "ray.init(num_cpus=1, ignore_reinit_error=True, log_to_driver=False)\n",
    "ModelCatalog.register_custom_model(\n",
    "        \"tcnn\", TorchGNCNN\n",
    "    )\n",
    "# Create the Trainer.\n",
    "algo = ppo.PPO(\n",
    "        env=\"L5-CLE-V1\",\n",
    "        config={\n",
    "            'num_worker': 1,\n",
    "            'disable_env_checking':True,\n",
    "            \"framework\": \"torch\",\n",
    "            # \"model\": {\n",
    "            #     \"custom_model\": \"GN_CNN_torch_model\",\n",
    "            #     \"custom_model_config\": {'feature_dim':128},\n",
    "            # },\n",
    "            # \"output\": \"/home/pronton/rl/l5kit/examples/RL/notebooks/logs/l5env2-out\", \n",
    "            # \"output_max_file_size\": 5000000,\n",
    "            '_disable_preprocessor_api': True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "for i in range(2):\n",
    "    result = algo.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_eps_length = 10\n",
    "train_sim_cfg = SimulationConfigGym()\n",
    "train_sim_cfg.num_simulation_steps = train_eps_length + 1\n",
    "\n",
    "env_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "# env = L5Env2(**env_kwargs)\n",
    "# env1_kwargs = {'env_config_path': env_config_path, 'use_kinematic': True, 'sim_cfg': train_sim_cfg}\n",
    "# env1 = L5Env(**env_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L5env2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo = ppo.PPO(\n",
    "        env=\"L5-CLE-V2\",\n",
    "        config={\n",
    "            'disable_env_checking':True,\n",
    "            \"framework\": \"torch\",\n",
    "            'log_level': 'INFO',\n",
    "            'num_gpu': 1,\n",
    "            'train_batch_size': 1,\n",
    "            'sgd_minibatch_size': 1,\n",
    "            'num_sgd_iter': 1,\n",
    "            'seed': 42,\n",
    "            'batch_mode': 'truncate_episodes',\n",
    "            # \"rollout_fragment_length\": 32,\n",
    "            \"model\": {\n",
    "                \"custom_model\": \"TorchSharedAttentionModel\",\n",
    "                # Extra kwargs to be passed to your model's c'tor.\n",
    "                \"custom_model_config\": {'cfg':cfg},\n",
    "            },\n",
    "            # \"output\": \"/home/pronton/rl/l5kit/examples/RL/notebooks/logs/l5env2-out\", \n",
    "            # \"output_max_file_size\": 5000000,\n",
    "            '_disable_preprocessor_api': True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "for i in range(1):\n",
    "    result = algo.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6df7c2a3d813445d6b3c74a479f8d37af444dbb4628cead36b7b0d6872de20bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
